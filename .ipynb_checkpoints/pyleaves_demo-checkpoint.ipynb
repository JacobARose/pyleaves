{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, navigate to your chosen working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "%cd ~/..\n",
    "%pwd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacob/miniconda2/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "random_seed = 34\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "import dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stuf import stuf\n",
    "\n",
    "import tensorflow as tf;\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "gpu=5\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='5'#str(gpu)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "print(get_available_gpus())\n",
    "\n",
    "import pyleaves\n",
    "\n",
    "from pyleaves import leavesdb\n",
    "from pyleaves.data_pipeline.tensorpack_loaders import get_multiprocess_dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benchmark',\n",
       " 'StubOutForTesting',\n",
       " 'TestCase',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_deprecation_wrapper',\n",
       " '_sys',\n",
       " 'assert_equal_graph_def',\n",
       " 'benchmark_config',\n",
       " 'compute_gradient',\n",
       " 'compute_gradient_error',\n",
       " 'create_local_cluster',\n",
       " 'get_temp_dir',\n",
       " 'gpu_device_name',\n",
       " 'is_built_with_cuda',\n",
       " 'is_gpu_available',\n",
       " 'main',\n",
       " 'mock',\n",
       " 'test_src_dir_path']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.** Initialize and connect to database in local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_db = leavesdb.init_local_db()\n",
    "\n",
    "db = dataset.connect(f'sqlite:///{local_db}', row_type=stuf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.** Print a summary of the database's contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leavesdb.summarize_db(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.** Select a subset of datasets\n",
    "##### Here we select the Fossil dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = leavesdb.db_query.load_Fossil_data(db)\n",
    "\n",
    "data = leavesdb.db_query.load_Leaves_data(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.** Encode labels as integers for feeding into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pyleaves.data_pipeline.preprocessing.encode_labels(data)\n",
    "\n",
    "data_df.sample(frac=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_counts(data_df, verbose=True):\n",
    "    labels, label_counts = np.unique(data_df['label'], return_counts=True)\n",
    "    if verbose:\n",
    "        print('label : count')\n",
    "        for label, count in zip(labels, label_counts):\n",
    "            print(label,' : ', count)\n",
    "    return labels, label_counts\n",
    "    \n",
    "def filter_low_count_labels(data_df, threshold=2, verbose = True):\n",
    "    '''\n",
    "    Function for omitting samples that belong to a class with a population size below the threshold. Used primarily for omitting classes with only 1 sample.\n",
    "    '''\n",
    "    labels, label_counts = np.unique(data_df['label'], return_counts=True)\n",
    "    filtered_labels = np.where(label_counts >= threshold)[0]\n",
    "    filtered_data = data_df[data_df['label'].isin(filtered_labels)]\n",
    "    if verbose:\n",
    "        print(f'Selecting only samples that belong to a class with population >= {threshold} samples')\n",
    "        print(f'Previous num_classes = {len(label_counts)}, new num_classes = {len(filtered_labels)}')\n",
    "        print(f'Previous data_df.shape = {data_df.shape}, new data_df.shape = {filtered_data.shape}')\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "val_size = 0.25\n",
    "\n",
    "data_df = filter_low_count_labels(data_df, threshold=3, verbose = True)\n",
    "\n",
    "train_data, test_data = train_test_split(data_df, test_size=test_size, random_state=random_seed, shuffle=True, stratify=data_df['label'])\n",
    "train_data, val_data = train_test_split(train_data, test_size=val_size, random_state=random_seed, shuffle=True, stratify=train_data['label'])\n",
    "\n",
    "# train_gen = get_multiprocess_dataflow(train_data['path'], train_data['label'], size=(299,299), batch_size=32, num_prefetch=25, num_proc=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Let's set up our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import tensorflow_io as tfio\n",
    "\n",
    "# import toolz\n",
    "\n",
    "\n",
    "# def get_class_frequencies(labels, ylim=(0,900)):\n",
    "#     class_frequencies = toolz.frequencies(labels)\n",
    "\n",
    "#     keys=[]\n",
    "#     values=[]\n",
    "#     for k, v in class_frequencies.items():\n",
    "#         keys.append(k)\n",
    "#         values.append(v)\n",
    "#     keys = np.array(keys)\n",
    "#     values = np.array(values)\n",
    "\n",
    "#     fig, axes = plt.subplots(1,2,figsize=(15,15))\n",
    "    \n",
    "#     ik = np.argsort(keys)[::-1]\n",
    "#     axes[0].bar(keys[ik], values[ik])\n",
    "#     axes[0].set_ylim(*ylim)\n",
    "#     axes[0].set_title('frequency vs labels in integer order')\n",
    "    \n",
    "#     ix = np.argsort(values)[::-1]\n",
    "#     axes[1].bar(range(len(ix)),values[ix])\n",
    "#     axes[1].set_ylim(*ylim)\n",
    "#     axes[1].set_title('frequency vs labels ordered by decreasing frequency')\n",
    "    \n",
    "plot_class_frequencies = leavesdb.utils.plot_class_frequencies\n",
    "    \n",
    "plot_class_frequencies(labels=train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(data_df['label']))\n",
    "img_size = [299,299]\n",
    "channels = 3\n",
    "batch_size = 32\n",
    "learning_rate=0.01\n",
    "num_epochs = 1\n",
    "\n",
    "def parse_function(filename, label):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.io.decode_jpeg(img, channels=channels)#, dtype=tf.float32)\n",
    "    img = tf.image.resize(img, img_size)\n",
    "    return img, label #{'image':img, 'label':label}\n",
    "\n",
    "# def train_preprocess(img, label):\n",
    "#     img = tf.image.resize(img, img_size)\n",
    "#     return {'image':img, 'label':label}\n",
    "    \n",
    "\n",
    "def get_tf_dataset(filenames, labels):\n",
    "    data = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    data = data.shuffle(len(filenames))\n",
    "    data = data.interleave(lambda x: tf.data.Dataset(x).map(parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE), cycle_length=4, block_length=16)\n",
    "#     data = data.map(train_preprocess, num_parallel_calls=4)\n",
    "    data = data.batch(batch_size)\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#     data = data.apply(tf.data.experimental.prefetch_to_device('/device:GPU:0'))\n",
    "    return data\n",
    "\n",
    "train_dataset = get_tf_dataset(filenames = train_data['path'].values, labels = train_data['label'].values)\n",
    "val_dataset = get_tf_dataset(filenames = val_data['path'].values, labels = val_data['label'].values)\n",
    "\n",
    "\n",
    "def decode_labels(data_df):\n",
    "    data_df=data_df.groupby('label', group_keys=False).apply(lambda df: df.sample(1).loc[:,['label','family']])\n",
    "    data_df.sort_values(by='label', inplace=True)\n",
    "    data_df.set_index(keys='label',drop=True, inplace=True)\n",
    "    data_df = data_df.to_dict()\n",
    "    \n",
    "    return data_df['family']\n",
    "\n",
    "\n",
    "\n",
    "label_map = decode_labels(data_df=train_data)\n",
    "\n",
    "label_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in  train_dataset.take(1):\n",
    "    image_batch = features[0].numpy().astype(np.int)\n",
    "    label_batch = features[1].numpy().astype(np.int)\n",
    "\n",
    "plot_image_grid = pyleaves.analysis.img_utils.plot_image_grid\n",
    "    \n",
    "    \n",
    "plot_image_grid(image_batch, label_batch, x_plots = 4, y_plots = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_data['label'] = train_data['label'].astype(str)\n",
    "\n",
    "datagen_flow = datagen.flow_from_dataframe(train_data.iloc[:100,:], x_col='path', y_col='label', class_mode='sparse', batch_size=batch_size)\n",
    "\n",
    "a=next(datagen_flow)\n",
    "\n",
    "print(a[0].shape, a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "num_samples_train = len(train_data)\n",
    "num_samples_val = len(val_data)\n",
    "num_samples_test = len(test_data)\n",
    "print(num_samples_train)\n",
    "print(num_samples_val)\n",
    "print(num_samples_test)\n",
    "\n",
    "start_time = time.time()\n",
    "n=100\n",
    "total_time = 0\n",
    "try:\n",
    "    for i, features in enumerate(train_dataset.take(n)):\n",
    "#         print(i, features[0].shape, features[1].shape)\n",
    "        run_time = time.time()-start_time\n",
    "        total_time += run_time\n",
    "        print(f'Took {run_time:.2f} seconds')\n",
    "        start_time = time.time()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'finished {i} iterations')\n",
    "\n",
    "avg_time = total_time / i+1\n",
    "\n",
    "rate = (i+1)*batch_size/total_time\n",
    "\n",
    "print(f'Avg time = {avg_time:.2f} | Ran {i+1} iterations using batch size = {batch_size} & {batch_size*n} samples')\n",
    "print(f'rate = {rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyleaves.models.inception_v3.build_model(num_classes, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = pyleaves.models.inception_v3.train_model(model,\n",
    "# \t\t\t\ttrain_dataset,\n",
    "# \t\t\t\tvalidation_data=val_dataset, \n",
    "# \t\t\t\tsteps_per_epoch=int(num_samples_train//batch_size),\n",
    "# \t\t\t\tvalidation_steps=int(num_samples_val//batch_size),\n",
    "# \t\t\t\tmax_epochs=num_epochs,\n",
    "# # \t\t\t\tcallbacks=None,\n",
    "# \t\t\t\tworkers=5,\n",
    "# \t\t\t\tinitial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "                train_dataset,\n",
    "                validation_data=val_dataset, \n",
    "                steps_per_epoch=int(num_samples_train//batch_size),\n",
    "                validation_steps=int(num_samples_val//batch_size),\n",
    "                max_epochs=num_epochs,\n",
    "                # \t\t\t\tcallbacks=None,\n",
    "                workers=5,\n",
    "                initial_epoch=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] :  7\n",
      "OpenCV is built with OpenMP support. This usually results in poor performance. For details, see https://github.com/tensorpack/benchmarks/blob/master/ImageNet/benchmark-opencv-resize.py\n",
      "\n",
      "WARNING:tensorflow:From /home/jacob/projects/pyleaves_git_correction/pyleaves/pyleaves/leavesdb/tf_utils/tf_utils.py:27: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Set seeds [PYTHONHASHSEED, random, np.random, tf.set_random_seed] = 12321\n",
      "WARNING:tensorflow:From /home/jacob/projects/pyleaves_git_correction/pyleaves/pyleaves/leavesdb/tf_utils/tf_utils.py:48: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jacob/projects/pyleaves_git_correction/pyleaves/pyleaves/leavesdb/tf_utils/tf_utils.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jacob/projects/pyleaves_git_correction/pyleaves/pyleaves/leavesdb/tf_utils/tf_utils.py:52: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:89:00.0, compute capability: 6.1\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "WARNING:tensorflow:From /home/jacob/projects/pyleaves_git_correction/pyleaves/pyleaves/leavesdb/tf_utils/tf_utils.py:53: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from stuf import stuf\n",
    "import os\n",
    "\n",
    "gpu = 7\n",
    "seed = 12321\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "print('os.environ[\"CUDA_VISIBLE_DEVICES\"] : ',os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "from pyleaves.leavesdb.tf_utils.tf_utils import set_random_seed, reset_keras_session\n",
    "set_random_seed(seed)\n",
    "reset_keras_session()\n",
    "\n",
    "\n",
    "import pyleaves\n",
    "# from pyleaves import leavesdb\n",
    "from pyleaves.base.base_data_manager import DataManager\n",
    "from pyleaves.base.base_trainer import ModelBuilder, BaseTrainer\n",
    "from pyleaves.configs.config_v2 import BaseConfig\n",
    "from pyleaves.leavesdb import experiments_db, db_manager\n",
    "from pyleaves.leavesdb.experiments_db import DataBase, Table, TFRecordsTable, EXPERIMENTS_SCHEMA, TFRecordItem, EXPERIMENTS_DB\n",
    "from pyleaves.leavesdb.experiments_db import get_db_table, select_by_col, select_by_multicol\n",
    "from pyleaves.leavesdb.tf_utils.create_tfrecords import save_tfrecords\n",
    "from pyleaves.datasets import leaves_dataset, fossil_dataset, pnas_dataset, base_dataset\n",
    "from pyleaves.utils.create_experiments import create_experiment__A_train_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jacob/projects/pyleaves_git_correction/pyleaves/pyleaves/leavesdb/resources/leavesdb.db\n",
      "BEGINNING  run_id                         1000\n",
      "experiment_type    A_train_val_test\n",
      "dataset_A                      PNAS\n",
      "dataset_B                      None\n",
      "Name: 0, dtype: object\n",
      "train 0.4 (0, 2125)\n",
      "val 0.1 (2125, 2657)\n",
      "test 0.5 (2657, 5314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:44:57.138 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 52,\n",
      "  \"1\": 142,\n",
      "  \"2\": 97,\n",
      "  \"3\": 61,\n",
      "  \"4\": 56,\n",
      "  \"5\": 79,\n",
      "  \"6\": 73,\n",
      "  \"7\": 297,\n",
      "  \"8\": 69,\n",
      "  \"9\": 128,\n",
      "  \"10\": 100,\n",
      "  \"11\": 78,\n",
      "  \"12\": 168,\n",
      "  \"13\": 46,\n",
      "  \"14\": 146,\n",
      "  \"15\": 90,\n",
      "  \"16\": 178,\n",
      "  \"17\": 179,\n",
      "  \"18\": 86\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 2125 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/train_data.csv\n",
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/train_class_counts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:44:57.197 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 2.1508097165991904,\n",
      "  \"1\": 0.7876204595997035,\n",
      "  \"2\": 1.1530113944655453,\n",
      "  \"3\": 1.8334771354616048,\n",
      "  \"4\": 1.9971804511278195,\n",
      "  \"5\": 1.4157228514323783,\n",
      "  \"6\": 1.532083633741889,\n",
      "  \"7\": 0.3765727449937976,\n",
      "  \"8\": 1.6209000762776506,\n",
      "  \"9\": 0.873766447368421,\n",
      "  \"10\": 1.118421052631579,\n",
      "  \"11\": 1.4338731443994601,\n",
      "  \"12\": 0.6657268170426065,\n",
      "  \"13\": 2.431350114416476,\n",
      "  \"14\": 0.7660418168709445,\n",
      "  \"15\": 1.2426900584795322,\n",
      "  \"16\": 0.6283264340626848,\n",
      "  \"17\": 0.6248162305204351,\n",
      "  \"18\": 1.3004895960832312\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/train_class_weights.csv\n",
      "logged class counts and weights to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/train_class_counts.csv and /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/train_class_weights.csv, respectively\n",
      "Starting to split train subset with 2125 total samples into 10 shards\n",
      "converting 2125 images to tfrecord\n",
      "self.num_shards 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jacob/envs/pyleaves/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Container\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00000-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00001-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00002-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00003-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00004-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00005-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00006-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00007-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00008-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00009-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/train-00010-of-00010.tfrecord\n",
      "PNAS train took 203.29 sec to collect/convert to TFRecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:48:20.703 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 8,\n",
      "  \"1\": 45,\n",
      "  \"2\": 18,\n",
      "  \"3\": 18,\n",
      "  \"4\": 13,\n",
      "  \"5\": 20,\n",
      "  \"6\": 18,\n",
      "  \"7\": 80,\n",
      "  \"8\": 14,\n",
      "  \"9\": 23,\n",
      "  \"10\": 21,\n",
      "  \"11\": 25,\n",
      "  \"12\": 41,\n",
      "  \"13\": 14,\n",
      "  \"14\": 34,\n",
      "  \"15\": 19,\n",
      "  \"16\": 47,\n",
      "  \"17\": 50,\n",
      "  \"18\": 24\n",
      "}\n",
      "2020-05-14 22:48:20.751 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 3.5,\n",
      "  \"1\": 0.6222222222222222,\n",
      "  \"2\": 1.5555555555555556,\n",
      "  \"3\": 1.5555555555555556,\n",
      "  \"4\": 2.1538461538461537,\n",
      "  \"5\": 1.4,\n",
      "  \"6\": 1.5555555555555556,\n",
      "  \"7\": 0.35,\n",
      "  \"8\": 2.0,\n",
      "  \"9\": 1.2173913043478262,\n",
      "  \"10\": 1.3333333333333333,\n",
      "  \"11\": 1.12,\n",
      "  \"12\": 0.6829268292682927,\n",
      "  \"13\": 2.0,\n",
      "  \"14\": 0.8235294117647058,\n",
      "  \"15\": 1.4736842105263157,\n",
      "  \"16\": 0.5957446808510638,\n",
      "  \"17\": 0.56,\n",
      "  \"18\": 1.1666666666666667\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 532 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/val_data.csv\n",
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/val_class_counts.csv\n",
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/val_class_weights.csv\n",
      "logged class counts and weights to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/val_class_counts.csv and /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/val_class_weights.csv, respectively\n",
      "Starting to split val subset with 532 total samples into 10 shards\n",
      "converting 532 images to tfrecord\n",
      "self.num_shards 10\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00000-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00001-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00002-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00003-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00004-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00005-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00006-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00007-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00008-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00009-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/val-00010-of-00010.tfrecord\n",
      "PNAS val took 50.50 sec to collect/convert to TFRecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:49:11.619 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 63,\n",
      "  \"1\": 163,\n",
      "  \"2\": 129,\n",
      "  \"3\": 59,\n",
      "  \"4\": 61,\n",
      "  \"5\": 92,\n",
      "  \"6\": 93,\n",
      "  \"7\": 399,\n",
      "  \"8\": 101,\n",
      "  \"9\": 160,\n",
      "  \"10\": 71,\n",
      "  \"11\": 90,\n",
      "  \"12\": 225,\n",
      "  \"13\": 74,\n",
      "  \"14\": 185,\n",
      "  \"15\": 98,\n",
      "  \"16\": 224,\n",
      "  \"17\": 226,\n",
      "  \"18\": 144\n",
      "}\n",
      "2020-05-14 22:49:11.656 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 2.219715956558062,\n",
      "  \"1\": 0.8579270261543429,\n",
      "  \"2\": 1.0840473276213791,\n",
      "  \"3\": 2.370205173951829,\n",
      "  \"4\": 2.292493528904228,\n",
      "  \"5\": 1.5200228832951945,\n",
      "  \"6\": 1.5036785512167516,\n",
      "  \"7\": 0.3504814668249571,\n",
      "  \"8\": 1.3845752996352267,\n",
      "  \"9\": 0.8740131578947369,\n",
      "  \"10\": 1.9696071163825055,\n",
      "  \"11\": 1.5538011695906433,\n",
      "  \"12\": 0.6215204678362574,\n",
      "  \"13\": 1.8897581792318634,\n",
      "  \"14\": 0.7559032716927454,\n",
      "  \"15\": 1.4269602577873255,\n",
      "  \"16\": 0.6242951127819549,\n",
      "  \"17\": 0.6187703772706101,\n",
      "  \"18\": 0.971125730994152\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 2657 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/test_data.csv\n",
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/test_class_counts.csv\n",
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/test_class_weights.csv\n",
      "logged class counts and weights to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/test_class_counts.csv and /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/PNAS/test_class_weights.csv, respectively\n",
      "Starting to split test subset with 2657 total samples into 10 shards\n",
      "converting 2657 images to tfrecord\n",
      "self.num_shards 10\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00000-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00001-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00002-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00003-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00004-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00005-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00006-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00007-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00008-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00009-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/PNAS/test-00010-of-00010.tfrecord\n",
      "PNAS test took 251.19 sec to collect/convert to TFRecords\n",
      "Full experiment took a total of 507.2948501110077\n",
      "BEGINNING  run_id                         1100\n",
      "experiment_type    A_train_val_test\n",
      "dataset_A                    Fossil\n",
      "dataset_B                      None\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:53:23.442 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 13,\n",
      "  \"1\": 83,\n",
      "  \"4\": 12,\n",
      "  \"5\": 21,\n",
      "  \"6\": 96,\n",
      "  \"7\": 25,\n",
      "  \"8\": 67,\n",
      "  \"9\": 305,\n",
      "  \"12\": 375,\n",
      "  \"13\": 30,\n",
      "  \"15\": 18,\n",
      "  \"16\": 8,\n",
      "  \"18\": 24,\n",
      "  \"19\": 6,\n",
      "  \"20\": 162,\n",
      "  \"21\": 70,\n",
      "  \"22\": 86,\n",
      "  \"24\": 412,\n",
      "  \"25\": 614,\n",
      "  \"26\": 11\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.4 (0, 2438)\n",
      "val 0.1 (2438, 3048)\n",
      "test 0.5 (3048, 6096)\n",
      "saved 2438 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/train_data.csv\n",
      "saved 20 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/train_class_counts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:53:23.558 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 9.376923076923077,\n",
      "  \"1\": 1.4686746987951806,\n",
      "  \"4\": 10.158333333333333,\n",
      "  \"5\": 5.804761904761905,\n",
      "  \"6\": 1.2697916666666667,\n",
      "  \"7\": 4.876,\n",
      "  \"8\": 1.819402985074627,\n",
      "  \"9\": 0.39967213114754097,\n",
      "  \"12\": 0.32506666666666667,\n",
      "  \"13\": 4.0633333333333335,\n",
      "  \"15\": 6.772222222222222,\n",
      "  \"16\": 15.2375,\n",
      "  \"18\": 5.079166666666667,\n",
      "  \"19\": 20.316666666666666,\n",
      "  \"20\": 0.7524691358024691,\n",
      "  \"21\": 1.7414285714285713,\n",
      "  \"22\": 1.4174418604651162,\n",
      "  \"24\": 0.295873786407767,\n",
      "  \"25\": 0.1985342019543974,\n",
      "  \"26\": 11.081818181818182\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 20 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/train_class_weights.csv\n",
      "logged class counts and weights to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/train_class_counts.csv and /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/train_class_weights.csv, respectively\n",
      "Starting to split train subset with 2438 total samples into 10 shards\n",
      "converting 2438 images to tfrecord\n",
      "self.num_shards 10\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00000-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00001-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00002-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00003-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00004-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00005-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00006-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00007-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00008-of-00010.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:57:39.007 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"1\": 26,\n",
      "  \"4\": 3,\n",
      "  \"5\": 3,\n",
      "  \"6\": 28,\n",
      "  \"7\": 7,\n",
      "  \"8\": 8,\n",
      "  \"9\": 68,\n",
      "  \"12\": 105,\n",
      "  \"13\": 4,\n",
      "  \"15\": 1,\n",
      "  \"16\": 2,\n",
      "  \"18\": 9,\n",
      "  \"19\": 2,\n",
      "  \"20\": 38,\n",
      "  \"21\": 18,\n",
      "  \"22\": 24,\n",
      "  \"24\": 113,\n",
      "  \"25\": 148,\n",
      "  \"26\": 3\n",
      "}\n",
      "2020-05-14 22:57:39.026 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"1\": 1.2348178137651822,\n",
      "  \"4\": 10.701754385964913,\n",
      "  \"5\": 10.701754385964913,\n",
      "  \"6\": 1.1466165413533835,\n",
      "  \"7\": 4.586466165413534,\n",
      "  \"8\": 4.0131578947368425,\n",
      "  \"9\": 0.47213622291021673,\n",
      "  \"12\": 0.3057644110275689,\n",
      "  \"13\": 8.026315789473685,\n",
      "  \"15\": 32.10526315789474,\n",
      "  \"16\": 16.05263157894737,\n",
      "  \"18\": 3.5672514619883042,\n",
      "  \"19\": 16.05263157894737,\n",
      "  \"20\": 0.8448753462603878,\n",
      "  \"21\": 1.7836257309941521,\n",
      "  \"22\": 1.337719298245614,\n",
      "  \"24\": 0.2841173730787145,\n",
      "  \"25\": 0.21692745376955902,\n",
      "  \"26\": 10.701754385964913\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00009-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/train-00010-of-00010.tfrecord\n",
      "Fossil train took 255.30 sec to collect/convert to TFRecords\n",
      "saved 610 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/val_data.csv\n",
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/val_class_counts.csv\n",
      "saved 19 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/val_class_weights.csv\n",
      "logged class counts and weights to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/val_class_counts.csv and /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/val_class_weights.csv, respectively\n",
      "Starting to split val subset with 610 total samples into 10 shards\n",
      "converting 610 images to tfrecord\n",
      "self.num_shards 10\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00000-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00001-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00002-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00003-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00004-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00005-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00006-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00007-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00008-of-00010.tfrecord\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/val-00009-of-00010.tfrecord\n",
      "Fossil val took 66.63 sec to collect/convert to TFRecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 22:58:45.975 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 20,\n",
      "  \"1\": 120,\n",
      "  \"4\": 11,\n",
      "  \"5\": 50,\n",
      "  \"6\": 130,\n",
      "  \"7\": 32,\n",
      "  \"8\": 69,\n",
      "  \"9\": 373,\n",
      "  \"12\": 463,\n",
      "  \"13\": 29,\n",
      "  \"15\": 18,\n",
      "  \"16\": 11,\n",
      "  \"18\": 33,\n",
      "  \"19\": 4,\n",
      "  \"20\": 229,\n",
      "  \"21\": 71,\n",
      "  \"22\": 124,\n",
      "  \"24\": 523,\n",
      "  \"25\": 730,\n",
      "  \"26\": 8\n",
      "}\n",
      "2020-05-14 22:58:46.020 | INFO     | pyleaves.loggers.csv_logger:log_dict:52 - {\n",
      "  \"0\": 7.62,\n",
      "  \"1\": 1.27,\n",
      "  \"4\": 13.854545454545455,\n",
      "  \"5\": 3.048,\n",
      "  \"6\": 1.1723076923076923,\n",
      "  \"7\": 4.7625,\n",
      "  \"8\": 2.208695652173913,\n",
      "  \"9\": 0.40857908847184987,\n",
      "  \"12\": 0.32915766738660907,\n",
      "  \"13\": 5.255172413793104,\n",
      "  \"15\": 8.466666666666667,\n",
      "  \"16\": 13.854545454545455,\n",
      "  \"18\": 4.618181818181818,\n",
      "  \"19\": 38.1,\n",
      "  \"20\": 0.6655021834061136,\n",
      "  \"21\": 2.1464788732394364,\n",
      "  \"22\": 1.229032258064516,\n",
      "  \"24\": 0.291395793499044,\n",
      "  \"25\": 0.20876712328767122,\n",
      "  \"26\": 19.05\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 3048 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/test_data.csv\n",
      "saved 20 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/test_class_counts.csv\n",
      "saved 20 samples to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/test_class_weights.csv\n",
      "logged class counts and weights to /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/test_class_counts.csv and /media/data_cifs/jacob/Fossil_Project/data/csv_data/A_train_val_test/Fossil/test_class_weights.csv, respectively\n",
      "Starting to split test subset with 3048 total samples into 10 shards\n",
      "converting 3048 images to tfrecord\n",
      "self.num_shards 10\n",
      "Found pre-written tfrecord /media/data/jacob/Fossil_Project/data/tfrecord_data/A_train_val_test/Fossil/test-00000-of-00010.tfrecord\n"
     ]
    }
   ],
   "source": [
    "data_src_db = pyleaves.DATABASE_PATH #r'/home/jacob/projects/wilf_data_updates/leavesdb.db'\n",
    "print(pyleaves.DATABASE_PATH)\n",
    "\n",
    "# experiments_db.create_db()\n",
    "\n",
    "tables = experiments_db.get_db_contents()\n",
    "\n",
    "create_experiment__A_train_val_test(src_db=data_src_db, include_runs=['all']) #'1200'])\n",
    "get_db_table(tablename='tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = experiments_db.get_db_contents()\n",
    "experiment_view = select_by_col(table=tables['runs'],column='experiment_type',value='A+B_train_val_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_manager.analyze_db_contents(data_src_db)\n",
    "data_src_db = r'/home/jacob/projects/wilf_data_updates/leavesdb.db'\n",
    "src_db = data_src_db\n",
    "from pyleaves.datasets import leaves_dataset, fossil_dataset, pnas_dataset, base_dataset\n",
    "\n",
    "datasets = {\n",
    "            'PNAS': pnas_dataset.PNASDataset(src_db=src_db),\n",
    "            'Leaves': leaves_dataset.LeavesDataset(src_db=src_db),\n",
    "            'Fossil': fossil_dataset.FossilDataset(src_db=src_db)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.isfile('/media/data_cifs/jacob/Fossil_Project/opt_data/PNAS/Malvaceae/Malvaceae_Pseudobombax_argentinum_3662 {WolfeUSGS} [1.96x].jpg')\n",
    "# os.listdir('/media/data_cifs/jacob/Fossil_Project/opt_data/PNAS/Malvaceae/')\n",
    "\n",
    "# # type(datasets['Leaves'].data)\n",
    "# import pyleaves\n",
    "# from pyleaves import leavesdb\n",
    "# from pyleaves.datasets.base_dataset import BaseDataset\n",
    "\n",
    "# class LeavesDataset(BaseDataset):\n",
    "\n",
    "#     __version__ = '1.1'\n",
    "\n",
    "#     def __init__(self, src_db=pyleaves.DATABASE_PATH):\n",
    "#         super().__init__(name='Leaves', src_db=src_db)\n",
    "#         # super().__init__(name='Leaves2020', src_db=src_db)\n",
    "#         self._data = self.load_from_db()\n",
    "        \n",
    "# leaves_dataset.LeavesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAS Index(['path', 'family'], dtype='object')\n",
      "Leaves Index(['path', 'family'], dtype='object')\n",
      "Fossil Index(['path', 'family'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fossil:\n",
       "    num_samples: 6122\n",
       "    num_classes: 27\n",
       "    class_count_threshold: 0\n",
       "        "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k,v in datasets.items():\n",
    "    print(k,v.data.columns)\n",
    "\n",
    "datasets['PNAS']\n",
    "datasets['Leaves']\n",
    "datasets['Fossil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method savefig in module matplotlib.figure:\n",
      "\n",
      "savefig(fname, *, transparent=None, **kwargs) method of matplotlib.figure.Figure instance\n",
      "    Save the current figure.\n",
      "    \n",
      "    Call signature::\n",
      "    \n",
      "      savefig(fname, dpi=None, facecolor='w', edgecolor='w',\n",
      "              orientation='portrait', papertype=None, format=None,\n",
      "              transparent=False, bbox_inches=None, pad_inches=0.1,\n",
      "              frameon=None, metadata=None)\n",
      "    \n",
      "    The output formats available depend on the backend being used.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    fname : str or PathLike or file-like object\n",
      "        A path, or a Python file-like object, or\n",
      "        possibly some backend-dependent object such as\n",
      "        `matplotlib.backends.backend_pdf.PdfPages`.\n",
      "    \n",
      "        If *format* is not set, then the output format is inferred from\n",
      "        the extension of *fname*, if any, and from :rc:`savefig.format`\n",
      "        otherwise.  If *format* is set, it determines the output format.\n",
      "    \n",
      "        Hence, if *fname* is not a path or has no extension, remember to\n",
      "        specify *format* to ensure that the correct backend is used.\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    \n",
      "    dpi : [ *None* | scalar > 0 | 'figure' ]\n",
      "        The resolution in dots per inch.  If *None*, defaults to\n",
      "        :rc:`savefig.dpi`.  If 'figure', uses the figure's dpi value.\n",
      "    \n",
      "    quality : [ *None* | 1 <= scalar <= 100 ]\n",
      "        The image quality, on a scale from 1 (worst) to 95 (best).\n",
      "        Applicable only if *format* is jpg or jpeg, ignored otherwise.\n",
      "        If *None*, defaults to :rc:`savefig.jpeg_quality` (95 by default).\n",
      "        Values above 95 should be avoided; 100 completely disables the\n",
      "        JPEG quantization stage.\n",
      "    \n",
      "    optimize : bool\n",
      "        If *True*, indicates that the JPEG encoder should make an extra\n",
      "        pass over the image in order to select optimal encoder settings.\n",
      "        Applicable only if *format* is jpg or jpeg, ignored otherwise.\n",
      "        Is *False* by default.\n",
      "    \n",
      "    progressive : bool\n",
      "        If *True*, indicates that this image should be stored as a\n",
      "        progressive JPEG file. Applicable only if *format* is jpg or\n",
      "        jpeg, ignored otherwise. Is *False* by default.\n",
      "    \n",
      "    facecolor : color spec or None, optional\n",
      "        The facecolor of the figure; if *None*, defaults to\n",
      "        :rc:`savefig.facecolor`.\n",
      "    \n",
      "    edgecolor : color spec or None, optional\n",
      "        The edgecolor of the figure; if *None*, defaults to\n",
      "        :rc:`savefig.edgecolor`\n",
      "    \n",
      "    orientation : {'landscape', 'portrait'}\n",
      "        Currently only supported by the postscript backend.\n",
      "    \n",
      "    papertype : str\n",
      "        One of 'letter', 'legal', 'executive', 'ledger', 'a0' through\n",
      "        'a10', 'b0' through 'b10'. Only supported for postscript\n",
      "        output.\n",
      "    \n",
      "    format : str\n",
      "        The file format, e.g. 'png', 'pdf', 'svg', ... The behavior when\n",
      "        this is unset is documented under *fname*.\n",
      "    \n",
      "    transparent : bool\n",
      "        If *True*, the axes patches will all be transparent; the\n",
      "        figure patch will also be transparent unless facecolor\n",
      "        and/or edgecolor are specified via kwargs.\n",
      "        This is useful, for example, for displaying\n",
      "        a plot on top of a colored background on a web page.  The\n",
      "        transparency of these patches will be restored to their\n",
      "        original values upon exit of this function.\n",
      "    \n",
      "    bbox_inches : str or `~matplotlib.transforms.Bbox`, optional\n",
      "        Bbox in inches. Only the given portion of the figure is\n",
      "        saved. If 'tight', try to figure out the tight bbox of\n",
      "        the figure. If None, use savefig.bbox\n",
      "    \n",
      "    pad_inches : scalar, optional\n",
      "        Amount of padding around the figure when bbox_inches is\n",
      "        'tight'. If None, use savefig.pad_inches\n",
      "    \n",
      "    bbox_extra_artists : list of `~matplotlib.artist.Artist`, optional\n",
      "        A list of extra artists that will be considered when the\n",
      "        tight bbox is calculated.\n",
      "    \n",
      "    metadata : dict, optional\n",
      "        Key/value pairs to store in the image metadata. The supported keys\n",
      "        and defaults depend on the image format and backend:\n",
      "    \n",
      "        - 'png' with Agg backend: See the parameter ``metadata`` of\n",
      "          `~.FigureCanvasAgg.print_png`.\n",
      "        - 'pdf' with pdf backend: See the parameter ``metadata`` of\n",
      "          `~.backend_pdf.PdfPages`.\n",
      "        - 'eps' and 'ps' with PS backend: Only 'Creator' is supported.\n",
      "    \n",
      "    pil_kwargs : dict, optional\n",
      "        Additional keyword arguments that are passed to `PIL.Image.save`\n",
      "        when saving the figure.  Only applicable for formats that are saved\n",
      "        using Pillow, i.e. JPEG, TIFF, and (if the keyword is set to a\n",
      "        non-None value) PNG.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fig.savefig)\n",
    "\n",
    "\n",
    "import io\n",
    "buffer = io.BytesIO()\n",
    "fig.savefig(buffer, format='png')\n",
    "buffer.seek(0)\n",
    "img = tf.image.decode_png(buffer.getvalue(), channels=4)\n",
    "img = tf.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DateTime' from 'datetime' (/media/data/conda/jacob/envs/pyleaves/lib/python3.7/datetime.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cc385d1c2c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDateTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DateTime' from 'datetime' (/media/data/conda/jacob/envs/pyleaves/lib/python3.7/datetime.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAXYEAR',\n",
       " 'MINYEAR',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'date',\n",
       " 'datetime',\n",
       " 'datetime_CAPI',\n",
       " 'sys',\n",
       " 'time',\n",
       " 'timedelta',\n",
       " 'timezone',\n",
       " 'tzinfo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "dir(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rsub__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " 'astimezone',\n",
       " 'combine',\n",
       " 'ctime',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dst',\n",
       " 'fold',\n",
       " 'fromisoformat',\n",
       " 'fromordinal',\n",
       " 'fromtimestamp',\n",
       " 'hour',\n",
       " 'isocalendar',\n",
       " 'isoformat',\n",
       " 'isoweekday',\n",
       " 'max',\n",
       " 'microsecond',\n",
       " 'min',\n",
       " 'minute',\n",
       " 'month',\n",
       " 'now',\n",
       " 'replace',\n",
       " 'resolution',\n",
       " 'second',\n",
       " 'strftime',\n",
       " 'strptime',\n",
       " 'time',\n",
       " 'timestamp',\n",
       " 'timetuple',\n",
       " 'timetz',\n",
       " 'today',\n",
       " 'toordinal',\n",
       " 'tzinfo',\n",
       " 'tzname',\n",
       " 'utcfromtimestamp',\n",
       " 'utcnow',\n",
       " 'utcoffset',\n",
       " 'utctimetuple',\n",
       " 'weekday',\n",
       " 'year']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=datetime.datetime(2020, 4, 20)\n",
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "a=datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon-04-20-2020_18-57-21'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime('%a-%m-%d-%Y_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GradientTape in module tensorflow.python.eager.backprop:\n",
      "\n",
      "class GradientTape(builtins.object)\n",
      " |  GradientTape(persistent=False, watch_accessed_variables=True)\n",
      " |  \n",
      " |  Record operations for automatic differentiation.\n",
      " |  \n",
      " |  Operations are recorded if they are executed within this context manager and\n",
      " |  at least one of their inputs is being \"watched\".\n",
      " |  \n",
      " |  Trainable variables (created by `tf.Variable` or `tf.compat.v1.get_variable`,\n",
      " |  where `trainable=True` is default in both cases) are automatically watched.\n",
      " |  Tensors can be manually watched by invoking the `watch` method on this context\n",
      " |  manager.\n",
      " |  \n",
      " |  For example, consider the function `y = x * x`. The gradient at `x = 3.0` can\n",
      " |  be computed as:\n",
      " |  \n",
      " |  ```python\n",
      " |  x = tf.constant(3.0)\n",
      " |  with tf.GradientTape() as g:\n",
      " |    g.watch(x)\n",
      " |    y = x * x\n",
      " |  dy_dx = g.gradient(y, x) # Will compute to 6.0\n",
      " |  ```\n",
      " |  \n",
      " |  GradientTapes can be nested to compute higher-order derivatives. For example,\n",
      " |  \n",
      " |  ```python\n",
      " |  x = tf.constant(3.0)\n",
      " |  with tf.GradientTape() as g:\n",
      " |    g.watch(x)\n",
      " |    with tf.GradientTape() as gg:\n",
      " |      gg.watch(x)\n",
      " |      y = x * x\n",
      " |    dy_dx = gg.gradient(y, x)     # Will compute to 6.0\n",
      " |  d2y_dx2 = g.gradient(dy_dx, x)  # Will compute to 2.0\n",
      " |  ```\n",
      " |  \n",
      " |  By default, the resources held by a GradientTape are released as soon as\n",
      " |  GradientTape.gradient() method is called. To compute multiple gradients over\n",
      " |  the same computation, create a persistent gradient tape. This allows multiple\n",
      " |  calls to the gradient() method as resources are released when the tape object\n",
      " |  is garbage collected. For example:\n",
      " |  \n",
      " |  ```python\n",
      " |  x = tf.constant(3.0)\n",
      " |  with tf.GradientTape(persistent=True) as g:\n",
      " |    g.watch(x)\n",
      " |    y = x * x\n",
      " |    z = y * y\n",
      " |  dz_dx = g.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
      " |  dy_dx = g.gradient(y, x)  # 6.0\n",
      " |  del g  # Drop the reference to the tape\n",
      " |  ```\n",
      " |  \n",
      " |  By default GradientTape will automatically watch any trainable variables that\n",
      " |  are accessed inside the context. If you want fine grained control over which\n",
      " |  variables are watched you can disable automatic tracking by passing\n",
      " |  `watch_accessed_variables=False` to the tape constructor:\n",
      " |  \n",
      " |  ```python\n",
      " |  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
      " |    tape.watch(variable_a)\n",
      " |    y = variable_a ** 2  # Gradients will be available for `variable_a`.\n",
      " |    z = variable_b ** 3  # No gradients will be available since `variable_b` is\n",
      " |                         # not being watched.\n",
      " |  ```\n",
      " |  \n",
      " |  Note that when using models you should ensure that your variables exist when\n",
      " |  using `watch_accessed_variables=False`. Otherwise it's quite easy to make your\n",
      " |  first iteration not have any gradients:\n",
      " |  \n",
      " |  ```python\n",
      " |  a = tf.keras.layers.Dense(32)\n",
      " |  b = tf.keras.layers.Dense(32)\n",
      " |  \n",
      " |  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
      " |    tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
      " |                             # `a.variables` will return an empty list and the\n",
      " |                             # tape will not be watching anything.\n",
      " |    result = b(a(inputs))\n",
      " |    tape.gradient(result, a.variables)  # The result of this computation will be\n",
      " |                                        # a list of `None`s since a's variables\n",
      " |                                        # are not being watched.\n",
      " |  ```\n",
      " |  \n",
      " |  Note that only tensors with real or complex dtypes are differentiable.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Enters a context inside which operations are recorded on this tape.\n",
      " |  \n",
      " |  __exit__(self, typ, value, traceback)\n",
      " |      Exits the recording context, no further operations are traced.\n",
      " |  \n",
      " |  __init__(self, persistent=False, watch_accessed_variables=True)\n",
      " |      Creates a new GradientTape.\n",
      " |      \n",
      " |      Args:\n",
      " |        persistent: Boolean controlling whether a persistent gradient tape\n",
      " |          is created. False by default, which means at most one call can\n",
      " |          be made to the gradient() method on this object.\n",
      " |        watch_accessed_variables: Boolean controlling whether the tape will\n",
      " |          automatically `watch` any (trainable) variables accessed while the tape\n",
      " |          is active. Defaults to True meaning gradients can be requested from any\n",
      " |          result computed in the tape derived from reading a trainable `Variable`.\n",
      " |          If False users must explicitly `watch` any `Variable`s they want to\n",
      " |          request gradients from.\n",
      " |  \n",
      " |  batch_jacobian(self, target, source, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      " |      Computes and stacks per-example jacobians.\n",
      " |      \n",
      " |      See [wikipedia article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant) for the\n",
      " |      definition of a Jacobian. This function is essentially an efficient\n",
      " |      implementation of the following:\n",
      " |      \n",
      " |      `tf.stack([self.jacobian(y[i], x[i]) for i in range(x.shape[0])])`.\n",
      " |      \n",
      " |      Note that compared to `GradientTape.jacobian` which computes gradient of\n",
      " |      each output value w.r.t each input value, this function is useful when\n",
      " |      `target[i,...]` is independent of `source[j,...]` for `j != i`. This\n",
      " |      assumption allows more efficient computation as compared to\n",
      " |      `GradientTape.jacobian`. The output, as well as intermediate activations,\n",
      " |      are lower dimensional and avoid a bunch of redundant zeros which would\n",
      " |      result in the jacobian computation given the independence assumption.\n",
      " |      \n",
      " |      Example usage:\n",
      " |      \n",
      " |      ```python\n",
      " |      with tf.GradientTape() as g:\n",
      " |        x = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
      " |        g.watch(x)\n",
      " |        y = x * x\n",
      " |      batch_jacobian = g.batch_jacobian(y, x)\n",
      " |      # batch_jacobian is [[[2,  0], [0,  4]], [[6,  0], [0,  8]]]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        target: A tensor with rank 2 or higher and with shape [b, y1, ..., y_n].\n",
      " |          `target[i,...]` should only depend on `source[i,...]`.\n",
      " |        source: A tensor with rank 2 or higher and with shape [b, x1, ..., x_m].\n",
      " |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      " |          alters the value which will be returned if the target and sources are\n",
      " |          unconnected. The possible values and effects are detailed in\n",
      " |          'UnconnectedGradients' and it defaults to 'none'.\n",
      " |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      " |          in parallel. This knob can be used to control the total memory usage.\n",
      " |        experimental_use_pfor: If true, uses pfor for computing the Jacobian. Else\n",
      " |          uses a tf.while_loop.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor `t` with shape [b, y_1, ..., y_n, x1, ..., x_m] where `t[i, ...]`\n",
      " |        is the jacobian of `target[i, ...]` w.r.t. `source[i, ...]`, i.e. stacked\n",
      " |        per-example jacobians.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      " |          enabled and without enabling experimental_use_pfor.\n",
      " |        ValueError: If vectorization of jacobian computation fails or if first\n",
      " |          dimension of `target` and `source` do not match.\n",
      " |  \n",
      " |  gradient(self, target, sources, output_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      " |      Computes the gradient using operations recorded in context of this tape.\n",
      " |      \n",
      " |      Args:\n",
      " |        target: a list or nested structure of Tensors or Variables to be\n",
      " |          differentiated.\n",
      " |        sources: a list or nested structure of Tensors or Variables. `target`\n",
      " |          will be differentiated against elements in `sources`.\n",
      " |        output_gradients: a list of gradients, one for each element of\n",
      " |          target. Defaults to None.\n",
      " |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      " |          alters the value which will be returned if the target and sources are\n",
      " |          unconnected. The possible values and effects are detailed in\n",
      " |          'UnconnectedGradients' and it defaults to 'none'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        a list or nested structure of Tensors (or IndexedSlices, or None),\n",
      " |        one for each element in `sources`. Returned structure is the same as\n",
      " |        the structure of `sources`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: if called inside the context of the tape, or if called more\n",
      " |         than once on a non-persistent tape.\n",
      " |        ValueError: if the target is a variable or if unconnected gradients is\n",
      " |         called with an unknown value.\n",
      " |  \n",
      " |  jacobian(self, target, sources, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      " |      Computes the jacobian using operations recorded in context of this tape.\n",
      " |      \n",
      " |      See [wikipedia article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant) for the\n",
      " |      definition of a Jacobian.\n",
      " |      \n",
      " |      Example usage:\n",
      " |      \n",
      " |      ```python\n",
      " |      with tf.GradientTape() as g:\n",
      " |        x  = tf.constant([1.0, 2.0])\n",
      " |        g.watch(x)\n",
      " |        y = x * x\n",
      " |      jacobian = g.jacobian(y, x)\n",
      " |      # jacobian value is [[2., 0.], [0., 4.]]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        target: Tensor to be differentiated.\n",
      " |        sources: a list or nested structure of Tensors or Variables. `target`\n",
      " |          will be differentiated against elements in `sources`.\n",
      " |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      " |          alters the value which will be returned if the target and sources are\n",
      " |          unconnected. The possible values and effects are detailed in\n",
      " |          'UnconnectedGradients' and it defaults to 'none'.\n",
      " |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      " |          in parallel. This knob can be used to control the total memory usage.\n",
      " |        experimental_use_pfor: If true, vectorizes the jacobian computation. Else\n",
      " |          falls back to a sequential while_loop. Vectorization can sometimes fail\n",
      " |          or lead to excessive memory usage. This option can be used to disable\n",
      " |          vectorization in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list or nested structure of Tensors (or None), one for each element in\n",
      " |        `sources`. Returned structure is the same as the structure of `sources`.\n",
      " |        Note if any gradient is sparse (IndexedSlices), jacobian function\n",
      " |        currently makes it dense and returns a Tensor instead. This may change in\n",
      " |        the future.\n",
      " |      \n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      " |          enabled and without enabling experimental_use_pfor.\n",
      " |        ValueError: If vectorization of jacobian computation fails.\n",
      " |  \n",
      " |  reset(self)\n",
      " |      Clears all information stored in this tape.\n",
      " |      \n",
      " |      Equivalent to exiting and reentering the tape context manager with a new\n",
      " |      tape. For example, the two following code blocks are equivalent:\n",
      " |      \n",
      " |      ```\n",
      " |      with tf.GradientTape() as t:\n",
      " |        loss = loss_fn()\n",
      " |      with tf.GradientTape() as t:\n",
      " |        loss += other_loss_fn()\n",
      " |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      " |      \n",
      " |      \n",
      " |      # The following is equivalent to the above\n",
      " |      with tf.GradientTape() as t:\n",
      " |        loss = loss_fn()\n",
      " |        t.reset()\n",
      " |        loss += other_loss_fn()\n",
      " |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      " |      ```\n",
      " |      \n",
      " |      This is useful if you don't want to exit the context manager for the tape,\n",
      " |      or can't because the desired reset point is inside a control flow construct:\n",
      " |      \n",
      " |      ```\n",
      " |      with tf.GradientTape() as t:\n",
      " |        loss = ...\n",
      " |        if loss > k:\n",
      " |          t.reset()\n",
      " |      ```\n",
      " |  \n",
      " |  stop_recording(self)\n",
      " |      Temporarily stops recording operations on this tape.\n",
      " |      \n",
      " |      Operations executed while this context manager is active will not be\n",
      " |      recorded on the tape. This is useful for reducing the memory used by tracing\n",
      " |      all computations.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      ```\n",
      " |        with tf.GradientTape(persistent=True) as t:\n",
      " |          loss = compute_loss(model)\n",
      " |          with t.stop_recording():\n",
      " |            # The gradient computation below is not traced, saving memory.\n",
      " |            grads = t.gradient(loss, model.variables)\n",
      " |      ```\n",
      " |      \n",
      " |      Yields:\n",
      " |        None\n",
      " |      Raises:\n",
      " |        RuntimeError: if the tape is not currently recording.\n",
      " |  \n",
      " |  watch(self, tensor)\n",
      " |      Ensures that `tensor` is being traced by this tape.\n",
      " |      \n",
      " |      Args:\n",
      " |        tensor: a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if it encounters something that is not a tensor.\n",
      " |  \n",
      " |  watched_variables(self)\n",
      " |      Returns variables watched by this tape in order of construction.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

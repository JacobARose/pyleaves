{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb;pdb.set_trace();print(__file__)\n",
    "from distutils.version import StrictVersion\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from collections import defaultdict, OrderedDict\n",
    "import gpustat\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra.experimental import compose, initialize, initialize_config_dir\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jacob/projects/pyleaves/pyleaves/configs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "config_dir='/home/jacob/projects/pyleaves/pyleaves/configs'\n",
    "os.chdir(config_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config_dir='/home/jacob/projects/pyleaves/pyleaves/configs/hydra/',\n",
    "         config_name=\"PNAS\",\n",
    "         overrides=[\"+db.user=me\"]) -> None:\n",
    "#     with initialize(config_path=config_path, job_name='test_app'):\n",
    "    with initialize_config_dir(config_dir=config_dir, job_name='test_app'):\n",
    "        cfg = compose(config_name=config_name, overrides=overrides)\n",
    "        pprint(OmegaConf.to_container(cfg))\n",
    "#     OmegaConf.set_struct(cfg, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'checkpoints_path': '???',\n",
      " 'log_dir': '???',\n",
      " 'model_dir': '???',\n",
      " 'n_jobs': 1,\n",
      " 'num_gpus': 1,\n",
      " 'pipeline': ['stage_0', 'stage_1'],\n",
      " 'results_dir': '???',\n",
      " 'saved_model_path': '???',\n",
      " 'stage_0': {'dataset': {'color_mode': 'grayscale',\n",
      "                         'dataset_name': 'Leaves-PNAS',\n",
      "                         'exclude_classes': ['notcataloged',\n",
      "                                             'notcatalogued',\n",
      "                                             'II. IDs, families uncertain',\n",
      "                                             'Unidentified'],\n",
      "                         'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10',\n",
      "                         'include_classes': [],\n",
      "                         'num_channels': 3,\n",
      "                         'num_classes': '???',\n",
      "                         'splits': {'train': 0.5, 'validation': 0.5},\n",
      "                         'target_size': [512, 512],\n",
      "                         'threshold': 10},\n",
      "             'model': {'METRICS': ['accuracy', 'precision', 'recall'],\n",
      "                       'loss': 'categorical_crossentropy',\n",
      "                       'lr': 4e-05,\n",
      "                       'misc': {'seed': 45},\n",
      "                       'model_name': 'resnet_50_v2',\n",
      "                       'optimizer': 'Adam',\n",
      "                       'regularization': {'l1': 0.0003},\n",
      "                       'training': {'augmentations': [{'flip': 1.0}],\n",
      "                                    'batch_size': 16,\n",
      "                                    'buffer_size': 200,\n",
      "                                    'frozen_layers': None,\n",
      "                                    'num_epochs': 150}}},\n",
      " 'stage_1': {'dataset': {'color_mode': 'grayscale',\n",
      "                         'dataset_name': 'Fossil',\n",
      "                         'exclude_classes': ['notcataloged',\n",
      "                                             'notcatalogued',\n",
      "                                             'II. IDs, families uncertain',\n",
      "                                             'Unidentified'],\n",
      "                         'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Fossil/ksplit_10',\n",
      "                         'include_classes': [],\n",
      "                         'num_channels': 3,\n",
      "                         'num_classes': '???',\n",
      "                         'splits': {'train': 0.5, 'validation': 0.5},\n",
      "                         'target_size': [512, 512],\n",
      "                         'threshold': 10},\n",
      "             'model': {'METRICS': ['accuracy', 'precision', 'recall'],\n",
      "                       'loss': 'categorical_crossentropy',\n",
      "                       'lr': 4e-05,\n",
      "                       'misc': {'seed': 45},\n",
      "                       'model_name': 'resnet_50_v2',\n",
      "                       'optimizer': 'Adam',\n",
      "                       'regularization': {'l1': 0.0003},\n",
      "                       'training': {'augmentations': [{'flip': 1.0}],\n",
      "                                    'batch_size': 16,\n",
      "                                    'buffer_size': 200,\n",
      "                                    'frozen_layers': None,\n",
      "                                    'num_epochs': 150}}},\n",
      " 'tfrecord_dir': '???'}\n"
     ]
    }
   ],
   "source": [
    "main(config_name='config', overrides=[])#'vgg6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setGPU():\n",
    "    stats = gpustat.GPUStatCollection.new_query()\n",
    "    ids = map(lambda gpu: int(gpu.entry['index']), stats)\n",
    "    ratios = map(lambda gpu: float(gpu.entry['memory.used'])/float(gpu.entry['memory.total']), stats)\n",
    "    pairs = list(zip(ids, ratios))\n",
    "    random.shuffle(pairs)\n",
    "    bestGPU = min(pairs, key=lambda x: x[1])[0]\n",
    "\n",
    "    print(\"setGPU: Setting GPU to: {}\".format(bestGPU))\n",
    "    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(bestGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from paleoai_data.utils.kfold_cross_validation import DataFold\n",
    "from paleoai_data.utils.kfold_cross_validation import generate_KFoldDataset, export_folds_to_csv, KFoldLoader #, prep_dataset\n",
    "# from pyleaves.utils.multiprocessing_utils import RunAsCUDASubprocess\n",
    "from pyleaves.utils import multiprocessing_utils\n",
    "    \n",
    "fold_dir = '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10'\n",
    "    \n",
    "kfold_loader = KFoldLoader(root_dir=fold_dir)\n",
    "kfold_iter = kfold_loader.iter_folds(repeats=1)\n",
    "# histories = Parallel(n_jobs=n_jobs)(delayed(train_single_fold)(fold=fold, cfg=copy.deepcopy(cfg_0), gpu_device=gpus[i]) for i, fold in enumerate(kfold_iter) if i < n_jobs)\n",
    "\n",
    "# print(f'Beginning training of models with fold_ids: {fold_ids}')\n",
    "for i, fold in enumerate(kfold_iter):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There is a new version of neptune-client 0.4.116 (installed: 0.4.115).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Project(jacobarose/sandbox)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(fold)\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import pyleaves\n",
    "import neptune\n",
    "import cloudpickle\n",
    "import itertools\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "# from pyleaves.mains.paleoai_main import restore_or_initialize_experiment, train_single_fold, log_config\n",
    "from pyleaves.mains.paleoai_main import restore_or_initialize_experiment,log_config\n",
    "from pyleaves.mains import paleoai_main\n",
    "\n",
    "\n",
    "\n",
    "CONFIG_DIR = str(Path(pyleaves.RESOURCES_DIR,'..','..','configs','hydra'))\n",
    "config_path = Path(CONFIG_DIR,'Leaves-PNAS.yaml')\n",
    "cfg = OmegaConf.load(config_path)\n",
    "cfg_0 = cfg.stage_0\n",
    "\n",
    "neptune.init(project_qualified_name=cfg.experiment.neptune_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(OmegaConf.to_container)\n",
    "# cfg_0_2 = copy.deepcopy(cfg_0)\n",
    "\n",
    "# worker_id = 0\n",
    "cfg = restore_or_initialize_experiment(cfg, restore_last=True, prefix='log_dir__', verbose=0)\n",
    "cfg_0 = copy.deepcopy(cfg.stage_0)\n",
    "\n",
    "cfg_0.misc['use_tfrecords'] = False\n",
    "\n",
    "# pickled_func = cloudpickle.dumps(train_single_fold)#(fold, copy.deepcopy(cfg_0), worker_id))\n",
    "# unpickled_func = cloudpickle.loads(pickled_func)\n",
    "\n",
    "# worker_id = 0\n",
    "# pickled_args = cloudpickle.dumps((fold, copy.deepcopy(cfg_0), worker_id))\n",
    "# unpickled_args = cloudpickle.loads(pickled_args)\n",
    "\n",
    "# with neptune.create_experiment(name=\"testing\"):\n",
    "#     unpickled_func(*unpickled_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.num_gpus=3\n",
    "n_jobs = 3\n",
    "\n",
    "def main():\n",
    "    histories = []\n",
    "    args = []\n",
    "    for worker_id, fold in enumerate(itertools.islice(kfold_iter, n_jobs)):\n",
    "        if worker_id >= 3:\n",
    "            break\n",
    "        args.append((fold, copy.deepcopy(cfg_0), worker_id))\n",
    "    args = tuple(args)\n",
    "    with neptune.create_experiment(name=f\"testing_worker-{worker_id}\"):\n",
    "        try:\n",
    "            pool = multiprocessing_utils.RunAsCUDASubprocess(num_gpus=cfg.num_gpus, memory_fraction=0.9)\n",
    "            result = pool.map(paleoai_main.train_single_fold,n_jobs, *args)\n",
    "            histories.append(result)\n",
    "        finally:\n",
    "            print(f'Finished, worker_id={worker_id}')\n",
    "\n",
    "                \n",
    "    return histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/jacobarose/sandbox/e/SAN-763\n",
      "Beginning n_jobs=3 for 3 total function calls\n",
      "WORKER 0 INITIATED\n",
      "WORKER 1 INITIATED\n",
      "setGPU: GPU:memory ratios initially visible to setGPU:\n",
      "[(2, 0.0008199409642505739),\n",
      " (0, 0.0008199409642505739),\n",
      " (1, 0.0008199409642505739),\n",
      " (7, 0.0008199409642505739),\n",
      " (3, 0.0008199409642505739),\n",
      " (6, 0.0008199409642505739),\n",
      " (4, 0.0008199409642505739),\n",
      " (5, 0.0008199409642505739)]\n",
      "setGPU: Setting GPU to: 2\n",
      "WORKER 2 INITIATED\n",
      "setGPU: GPU:memory ratios initially visible to setGPU:\n",
      "[(5, 0.0008199409642505739),\n",
      " (0, 0.0008199409642505739),\n",
      " (4, 0.0008199409642505739),\n",
      " (2, 0.0008199409642505739),\n",
      " (7, 0.0008199409642505739),\n",
      " (3, 0.0008199409642505739),\n",
      " (1, 0.0008199409642505739),\n",
      " (6, 0.0008199409642505739)]\n",
      "setGPU: Setting GPU to: 5\n",
      "setting memory growth failed, continuing anyway.\n",
      "setGPU: GPU:memory ratios initially visible to setGPU:\n",
      "[(2, 0.0008199409642505739),\n",
      " (3, 0.0008199409642505739),\n",
      " (1, 0.0008199409642505739),\n",
      " (0, 0.0008199409642505739),\n",
      " (5, 0.0008199409642505739),\n",
      " (7, 0.0008199409642505739),\n",
      " (6, 0.0008199409642505739),\n",
      " (4, 0.0008199409642505739)]\n",
      "setGPU: Setting GPU to: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/site-packages/scikitplot/plotters.py:37: DeprecationWarning: This module was deprecated in version 0.3.0 and its functions are spread throughout different modules. Please check the documentation and update your function calls as soon as possible. This module will be removed in 0.4.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting memory growth failed, continuing anyway.\n",
      "setting memory growth failed, continuing anyway.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/site-packages/scikitplot/plotters.py:37: DeprecationWarning: This module was deprecated in version 0.3.0 and its functions are spread throughout different modules. Please check the documentation and update your function calls as soon as possible. This module will be removed in 0.4.0\n",
      "  DeprecationWarning)\n",
      "/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/site-packages/scikitplot/plotters.py:37: DeprecationWarning: This module was deprecated in version 0.3.0 and its functions are spread throughout different modules. Please check the documentation and update your function calls as soon as possible. This module will be removed in 0.4.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "RUNNING: fold 1 in process None\n",
      "/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_01\n",
      "====================\n",
      "====================\n",
      "RUNNING: fold 2 in process 1\n",
      "/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_02\n",
      "====================\n",
      "====================\n",
      "RUNNING: fold 3 in process 2\n",
      "/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_03\n",
      "====================\n",
      "Starting fold 1\n",
      "inside log dataset\n",
      "updated cfg\n",
      "{'checkpoints_path': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints',\n",
      " 'dataset': {'color_mode': 'grayscale',\n",
      "             'dataset_name': 'Leaves-PNAS',\n",
      "             'exclude_classes': ['notcataloged',\n",
      "                                 'notcatalogued',\n",
      "                                 'II. IDs, families uncertain',\n",
      "                                 'Unidentified'],\n",
      "             'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10',\n",
      "             'include_classes': [],\n",
      "             'num_channels': 3,\n",
      "             'num_classes': 174,\n",
      "             'splits': {'train': 0.5, 'validation': 0.5},\n",
      "             'splits_size': {'test': 2112, 'train': 19002},\n",
      "             'target_size': [512, 512],\n",
      "             'threshold': 10},\n",
      " 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30',\n",
      " 'misc': {'samples_per_shard': 500, 'seed': 45, 'use_tfrecords': False},\n",
      " 'model': {'METRICS': ['accuracy', 'precision', 'recall'],\n",
      "           'loss': 'categorical_crossentropy',\n",
      "           'lr': 4e-05,\n",
      "           'model_name': 'resnet_50_v2',\n",
      "           'optimizer': 'Adam',\n",
      "           'regularization': {'l1': 0.0003}},\n",
      " 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir',\n",
      " 'steps_per_epoch': 1187,\n",
      " 'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_01',\n",
      " 'training': {'augmentations': [{'flip': 1.0}],\n",
      "              'batch_size': 16,\n",
      "              'buffer_size': 200,\n",
      "              'frozen_layers': None,\n",
      "              'num_epochs': 150},\n",
      " 'validation_steps': 132}\n",
      "Starting fold 2\n",
      "inside log dataset\n",
      "updated cfg\n",
      "{'checkpoints_path': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints',\n",
      " 'dataset': {'color_mode': 'grayscale',\n",
      "             'dataset_name': 'Leaves-PNAS',\n",
      "             'exclude_classes': ['notcataloged',\n",
      "                                 'notcatalogued',\n",
      "                                 'II. IDs, families uncertain',\n",
      "                                 'Unidentified'],\n",
      "             'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10',\n",
      "             'include_classes': [],\n",
      "             'num_channels': 3,\n",
      "             'num_classes': 174,\n",
      "             'splits': {'train': 0.5, 'validation': 0.5},\n",
      "             'splits_size': {'test': 2112, 'train': 19002},\n",
      "             'target_size': [512, 512],\n",
      "             'threshold': 10},\n",
      " 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30',\n",
      " 'misc': {'samples_per_shard': 500, 'seed': 45, 'use_tfrecords': False},\n",
      " 'model': {'METRICS': ['accuracy', 'precision', 'recall'],\n",
      "           'loss': 'categorical_crossentropy',\n",
      "           'lr': 4e-05,\n",
      "           'model_name'Starting fold 3: \n",
      "'resnet_50_v2'inside log dataset,\n",
      "           'optimizer'\n",
      ": 'Adam',\n",
      "           'regularization': {'l1': 0.0003}},\n",
      " 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir',\n",
      " 'steps_per_epoch': updated cfg1187\n",
      ",\n",
      " 'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_02'{,\n",
      " 'checkpoints_path''training': : '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints'{,\n",
      " 'augmentations''dataset': : [{'flip': 1.0}]{,\n",
      "              'color_mode''batch_size': : 'grayscale'16,\n",
      "             ,\n",
      "              'dataset_name''buffer_size': : 'Leaves-PNAS'200,\n",
      "             ,\n",
      "              'exclude_classes''frozen_layers': : [None'notcataloged',\n",
      "              ,\n",
      "                                 'num_epochs''notcatalogued': ,\n",
      "                                 150'II. IDs, families uncertain'},\n",
      "                                 ,\n",
      " 'Unidentified''validation_steps']: ,\n",
      "             132'fold_dir'}: \n",
      "'/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10',\n",
      "             'include_classes': [],\n",
      "             'num_channels': 3,\n",
      "             'num_classes': 174,\n",
      "             'splits': {'train': 0.5, 'validation': 0.5},\n",
      "             'splits_size': {'test': 2112, 'train': 19002},\n",
      "             'target_size': [512, 512],\n",
      "             'threshold': 10},\n",
      " 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30',\n",
      " 'misc': {'samples_per_shard': 500, 'seed': 45, 'use_tfrecords': False},\n",
      " 'model': {'METRICS': ['accuracy', 'precision', 'recall'],\n",
      "           'loss': 'categorical_crossentropy',\n",
      "           'lr': 4e-05,\n",
      "           'model_name': 'resnet_50_v2',\n",
      "           'optimizer': 'Adam',\n",
      "           'regularization': {'l1': 0.0003}},\n",
      " 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir',\n",
      " 'steps_per_epoch': 1187,\n",
      " 'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_03',\n",
      " 'training': {'augmentations': [{'flip': 1.0}],\n",
      "              'batch_size': 16,\n",
      "              'buffer_size': 200,\n",
      "              'frozen_layers': None,\n",
      "              'num_epochs': 150},\n",
      " 'validation_steps': 132}\n",
      "building callbacks\n",
      "Initiating model.fit for fold-1\n",
      "Initializing new checkpoint for model in epoch 0\n",
      "building callbacks\n",
      "Initiating model.fit for fold-3\n",
      "building callbacks\n",
      "Initiating model.fit for fold-2\n",
      "Initializing new checkpoint for model in epoch 0\n",
      "Initializing new checkpoint for model in epoch 0\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.425115). Check your callbacks.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    }
   ],
   "source": [
    "results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jacob/projects/pyleaves/pyleaves/mains/paleoai_main.py\u001b[0m(153)\u001b[0;36mtrain_single_fold\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    151 \u001b[0;31m    \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    152 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 153 \u001b[0;31m    \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfrecord_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfrecord_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    154 \u001b[0;31m    \u001b[0mensure_dir_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfrecord_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    155 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(cfg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: unexpected EOF while parsing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(cfg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'cfg' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  dir()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m    148 \u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mpyleaves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackupAndRestore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    149 \u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mpyleaves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneptune_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageLoggerCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneptune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    150 \u001b[0m    \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    151 \u001b[0m    \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    152 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 153 \u001b[0;31m    \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfrecord_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfrecord_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    154 \u001b[0m    \u001b[0mensure_dir_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfrecord_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    155 \u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    156 \u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    157 \u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'RUNNING: fold {fold.fold_id} in process {worker_id or \"None\"}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    158 \u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfrecord_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'K' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jacob/projects/pyleaves/pyleaves/utils/multiprocessing_utils.py\u001b[0m(47)\u001b[0;36m_subprocess_code\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     45 \u001b[0;31m        \u001b[0;31m# using cloudpickle because it is more flexible about what functions it will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m        \u001b[0;31m# pickle (lambda functions, notebook code, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 47 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     48 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     49 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  args\n",
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/multiprocessing/pool.py\u001b[0m(47)\u001b[0;36mstarmapstar\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     45 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 47 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     48 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     49 \u001b[0;31m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m     42 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     43 \u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     44 \u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     45 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     46 \u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 47 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     48 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     49 \u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     50 \u001b[0m\u001b[0;31m# Hack to embed stringification of remote traceback in local traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     51 \u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     52 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  args\n",
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/multiprocessing/pool.py\u001b[0m(121)\u001b[0;36mworker\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    119 \u001b[0;31m        \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 121 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    122 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    123 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/multiprocessing/pool.py\u001b[0m(657)\u001b[0;36mget\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    655 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    656 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 657 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    658 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    659 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/multiprocessing/pool.py\u001b[0m(276)\u001b[0;36mstarmap\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    274 \u001b[0;31m        \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    275 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m--> 276 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    277 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    278 \u001b[0;31m    def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jacob/projects/pyleaves/pyleaves/utils/multiprocessing_utils.py\u001b[0m(64)\u001b[0;36mmap\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     62 \u001b[0;31m                                    (\n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m                                        \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_fraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 64 \u001b[0;31m                                            \u001b[0;32mfor\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m                                    )\n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                )\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m     59 \u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     60 \u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     61 \u001b[0m                result = pool.starmap(RunAsCUDASubprocess._subprocess_code, (\n",
      "\u001b[1;32m     62 \u001b[0m                                    (\n",
      "\u001b[1;32m     63 \u001b[0m                                        \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_fraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 64 \u001b[0;31m                                            \u001b[0;32mfor\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     65 \u001b[0m                                    )\n",
      "\u001b[1;32m     66 \u001b[0m                                )\n",
      "\u001b[1;32m     67 \u001b[0m                            )\n",
      "\u001b[1;32m     68 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     69 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  dir()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['args', 'f', 'kwargs', 'n_jobs', 'pool', 'self']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  args\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self = <pyleaves.utils.multiprocessing_utils.RunAsCUDASubprocess object at 0x7f8b9782c410>\n",
      "f = <function train_single_fold at 0x7f8b980ef3b0>\n",
      "n_jobs = 2\n",
      "args = (((DataFold(fold_id=1)\n",
      "  19 columns\n",
      "  19002 train samples\n",
      "  2112 test samples, {'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir', 'dataset': {'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10', 'dataset_name': 'Leaves-PNAS', 'num_classes': '???', 'threshold': 10, 'color_mode': 'grayscale', 'num_channels': 3, 'target_size': [512, 512], 'splits': {'train': 0.5, 'validation': 0.5}, 'include_classes': [], 'exclude_classes': ['notcataloged', 'notcatalogued', 'II. IDs, families uncertain', 'Unidentified']}, 'model': {'model_name': 'resnet_50_v2', 'optimizer': 'Adam', 'loss': 'categorical_crossentropy', 'lr': 4e-05, 'regularization': {'l1': 0.0003}, 'METRICS': ['accuracy', 'precision', 'recall']}, 'training': {'batch_size': 16, 'buffer_size': 200, 'num_epochs': 150, 'frozen_layers': None, 'augmentations': [{'flip': 1.0}]}, 'misc': {'seed': 45, 'use_tfrecords': False, 'samples_per_shard': 500}, 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30', 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir', 'checkpoints_path': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints'}, 0), (DataFold(fold_id=2)\n",
      "  19 columns\n",
      "  19002 train samples\n",
      "  2112 test samples, {'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir', 'dataset': {'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10', 'dataset_name': 'Leaves-PNAS', 'num_classes': '???', 'threshold': 10, 'color_mode': 'grayscale', 'num_channels': 3, 'target_size': [512, 512], 'splits': {'train': 0.5, 'validation': 0.5}, 'include_classes': [], 'exclude_classes': ['notcataloged', 'notcatalogued', 'II. IDs, families uncertain', 'Unidentified']}, 'model': {'model_name': 'resnet_50_v2', 'optimizer': 'Adam', 'loss': 'categorical_crossentropy', 'lr': 4e-05, 'regularization': {'l1': 0.0003}, 'METRICS': ['accuracy', 'precision', 'recall']}, 'training': {'batch_size': 16, 'buffer_size': 200, 'num_epochs': 150, 'frozen_layers': None, 'augmentations': [{'flip': 1.0}]}, 'misc': {'seed': 45, 'use_tfrecords': False, 'samples_per_shard': 500}, 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30', 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir', 'checkpoints_path': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints'}, 1)),)\n",
      "kwargs = {}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(args[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  args[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self = <pyleaves.utils.multiprocessing_utils.RunAsCUDASubprocess object at 0x7f8b9782c410>\n",
      "f = <function train_single_fold at 0x7f8b980ef3b0>\n",
      "n_jobs = 2\n",
      "args = (((DataFold(fold_id=1)\n",
      "  19 columns\n",
      "  19002 train samples\n",
      "  2112 test samples, {'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir', 'dataset': {'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10', 'dataset_name': 'Leaves-PNAS', 'num_classes': '???', 'threshold': 10, 'color_mode': 'grayscale', 'num_channels': 3, 'target_size': [512, 512], 'splits': {'train': 0.5, 'validation': 0.5}, 'include_classes': [], 'exclude_classes': ['notcataloged', 'notcatalogued', 'II. IDs, families uncertain', 'Unidentified']}, 'model': {'model_name': 'resnet_50_v2', 'optimizer': 'Adam', 'loss': 'categorical_crossentropy', 'lr': 4e-05, 'regularization': {'l1': 0.0003}, 'METRICS': ['accuracy', 'precision', 'recall']}, 'training': {'batch_size': 16, 'buffer_size': 200, 'num_epochs': 150, 'frozen_layers': None, 'augmentations': [{'flip': 1.0}]}, 'misc': {'seed': 45, 'use_tfrecords': False, 'samples_per_shard': 500}, 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30', 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir', 'checkpoints_path': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints'}, 0), (DataFold(fold_id=2)\n",
      "  19 columns\n",
      "  19002 train samples\n",
      "  2112 test samples, {'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir', 'dataset': {'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10', 'dataset_name': 'Leaves-PNAS', 'num_classes': '???', 'threshold': 10, 'color_mode': 'grayscale', 'num_channels': 3, 'target_size': [512, 512], 'splits': {'train': 0.5, 'validation': 0.5}, 'include_classes': [], 'exclude_classes': ['notcataloged', 'notcatalogued', 'II. IDs, families uncertain', 'Unidentified']}, 'model': {'model_name': 'resnet_50_v2', 'optimizer': 'Adam', 'loss': 'categorical_crossentropy', 'lr': 4e-05, 'regularization': {'l1': 0.0003}, 'METRICS': ['accuracy', 'precision', 'recall']}, 'training': {'batch_size': 16, 'buffer_size': 200, 'num_epochs': 150, 'frozen_layers': None, 'augmentations': [{'flip': 1.0}]}, 'misc': {'seed': 45, 'use_tfrecords': False, 'samples_per_shard': 500}, 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30', 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir', 'checkpoints_path': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints'}, 1)),)\n",
      "kwargs = {}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.num_gpus=2\n",
    "n_jobs = 2\n",
    "import pdb\n",
    "\n",
    "# pool = multiprocessing_utils.RunAsCUDASubprocess(num_gpus=cfg.num_gpus, memory_fraction=0.9)\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def run_fold(*args):\n",
    "    pool = multiprocessing_utils.RunAsCUDASubprocess(num_gpus=cfg.num_gpus, memory_fraction=0.9)\n",
    "    return pool(paleoai_main.train_single_fold)(*args)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    histories = []\n",
    "    for worker_id, fold in enumerate(itertools.islice(kfold_iter, n_jobs)):\n",
    "        if worker_id >= 2:\n",
    "            break\n",
    "        with neptune.create_experiment(name=f\"testing_worker-{worker_id}\"):\n",
    "            try:\n",
    "#                 result = pool(paleoai_main.train_single_fold)(fold, copy.deepcopy(cfg_0), worker_id)\n",
    "                print(f'Awaiting, worker_id={worker_id}')\n",
    "                result = run_fold(fold, copy.deepcopy(cfg_0), worker_id)\n",
    "                histories.append(result)\n",
    "            finally:\n",
    "                print(f'Finished, worker_id={worker_id}')\n",
    "            continue\n",
    "                \n",
    "    return await asyncio.gather(*histories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_future = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/jacobarose/sandbox/e/SAN-753\n",
      "Awaiting, worker_id=0\n",
      "Finished, worker_id=0\n",
      "https://ui.neptune.ai/jacobarose/sandbox/e/SAN-754\n",
      "Awaiting, worker_id=1\n",
      "Finished, worker_id=1\n",
      "LEN(ARGS) = 3\n",
      "Closed process\n",
      "WORKER 0 INITIATED\n",
      "setGPU: GPU:memory ratios initially visible to setGPU:\n",
      "[(6, 0.0), (5, 0.0), (2, 0.0), (1, 0.0), (3, 0.0), (7, 0.0), (0, 0.0), (4, 0.0)]\n",
      "setGPU: Setting GPU to: 6\n",
      "setting memory growth failed, continuing anyway.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jacob/envs/pyleaves2/lib/python3.7/site-packages/scikitplot/plotters.py:37: DeprecationWarning: This module was deprecated in version 0.3.0 and its functions are spread throughout different modules. Please check the documentation and update your function calls as soon as possible. This module will be removed in 0.4.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "RUNNING: fold 1 in process None\n",
      "/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_01\n",
      "====================\n",
      "creating dataset\n",
      "Starting fold 1\n",
      "logging dataset\n",
      "inside log dataset\n",
      "updated cfg\n",
      "cfg\n",
      "<class 'omegaconf.dictconfig.DictConfig'>\n",
      "{'checkpoints_path': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir/checkpoints',\n",
      " 'dataset': {'color_mode': 'grayscale',\n",
      "             'dataset_name': 'Leaves-PNAS',\n",
      "             'exclude_classes': ['notcataloged',\n",
      "                                 'notcatalogued',\n",
      "                                 'II. IDs, families uncertain',\n",
      "                                 'Unidentified'],\n",
      "             'fold_dir': '/home/jacob/projects/paleoai_data/paleoai_data/v0_2/data/staged_data/Leaves-PNAS/ksplit_10',\n",
      "             'include_classes': [],\n",
      "             'num_channels': 3,\n",
      "             'num_classes': 174,\n",
      "             'splits': {'train': 0.5, 'validation': 0.5},\n",
      "             'splits_size': {'test': 2112, 'train': 19002},\n",
      "             'target_size': [512, 512],\n",
      "             'threshold': 10},\n",
      " 'log_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30',\n",
      " 'misc': {'samples_per_shard': 500, 'seed': 45, 'use_tfrecords': False},\n",
      " 'model': {'METRICS': ['accuracy', 'precision', 'recall'],\n",
      "           'loss': 'categorical_crossentropy',\n",
      "           'lr': 4e-05,\n",
      "           'model_name': 'resnet_50_v2',\n",
      "           'optimizer': 'Adam',\n",
      "           'regularization': {'l1': 0.0003}},\n",
      " 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir',\n",
      " 'steps_per_epoch': 1187,\n",
      " 'tfrecord_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/tfrecord_dir/fold_01',\n",
      " 'training': {'augmentations': [{'flip': 1.0}],\n",
      "              'batch_size': 16,\n",
      "              'buffer_size': 200,\n",
      "              'frozen_layers': None,\n",
      "              'num_epochs': 150},\n",
      " 'validation_steps': 132}\n",
      "<class 'omegaconf.dictconfig.DictConfig'> {'model_name': 'resnet_50_v2', 'optimizer': 'Adam', 'loss': 'categorical_crossentropy', 'lr': 4e-05, 'regularization': {'l1': 0.0003}, 'METRICS': ['accuracy', 'precision', 'recall'], 'base_learning_rate': None, 'input_shape': [512, 512, 3], 'model_dir': '/media/data/jacob/sandbox_logs/Leaves-PNAS_resnet_50_v2/log_dir__2020-08-19_07-57-30/model_dir', 'num_classes': 174, 'batch_size': 16, 'buffer_size': 200, 'num_epochs': 150, 'frozen_layers': None, 'augmentations': [{'flip': 1.0}]}\n",
      "picking model\n",
      "picked model\n",
      "Finished compiling model\n",
      "Initiating model.fit\n",
      "Train for 1187 steps, validate for 132 steps\n",
      "Initializing new checkpoint for model in epoch 0\n",
      "Epoch 2/150\n",
      " 704/1187 [================>.............].2416 - precision: 0.7640 - recall: 0.0945 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 3:59:04 - loss: 4.7096 - accuracy: 0.0312 - precision: 0.0000e+00 - recall: 0.0000e+00   - ETA: 2:42:27 - loss: 4.8398 - accuracy: 0.0208 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 2:03:51 - loss: 4.8496 - accuracy: 0.0312 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 1:40:50 - loss: 4.7169 - accuracy: 0.0750 - precision: 1.0000 - recall: 0.0125       - ETA: 1:25:24 - loss: 4.7388 - accuracy: 0.0729 - precision: 1.0000 - recall: 0.01 - ETA: 1:14:19 - loss: 4.8125 - accuracy: 0.0625 - precision: 1.0000 - recall: 0.00 - ETA: 1:06:12 - loss: 4.8174 - accuracy: 0.0703 - precision: 1.0000 - recall: 0.00 - ETA: 1:00:21 - loss: 4.8061 - accuracy: 0.0625 - precision: 1.0000 - recall: 0.00 - ETA: 58:19 - loss: 4.7346 - accuracy: 0.0812 - precision: 1.0000 - recall: 0.0125 - ETA: 56:52 - loss: 4.7141 - accuracy: 0.0966 - precision: 1.0000 - recall: 0.01 - ETA: 54:54 - loss: 4.7014 - accuracy: 0.0938 - precision: 1.0000 - recall: 0.01 - ETA: 53:51 - loss: 4.7133 - accuracy: 0.0962 - precision: 1.0000 - recall: 0.01 - ETA: 52:42 - loss: 4.7060 - accuracy: 0.0938 - precision: 1.0000 - recall: 0.01 - ETA: 52:26 - loss: 4.6992 - accuracy: 0.0958 - precision: 1.0000 - recall: 0.01 - ETA: 51:28 - loss: 4.6900 - accuracy: 0.0898 - precision: 0.7500 - recall: 0.01 - ETA: 50:27 - loss: 4.6777 - accuracy: 0.0919 - precision: 0.7500 - recall: 0.01 - ETA: 49:23 - loss: 4.6811 - accuracy: 0.0938 - precision: 0.7500 - recall: 0.01 - ETA: 48:29 - loss: 4.6543 - accuracy: 0.1020 - precision: 0.8000 - recall: 0.01 - ETA: 47:53 - loss: 4.6170 - accuracy: 0.1125 - precision: 0.8000 - recall: 0.01 - ETA: 47:01 - loss: 4.6148 - accuracy: 0.1161 - precision: 0.8000 - recall: 0.01 - ETA: 46:34 - loss: 4.6069 - accuracy: 0.1193 - precision: 0.6667 - recall: 0.01 - ETA: 46:38 - loss: 4.6104 - accuracy: 0.1168 - precision: 0.5714 - recall: 0.01 - ETA: 46:05 - loss: 4.5974 - accuracy: 0.1198 - precision: 0.5714 - recall: 0.01 - ETA: 45:30 - loss: 4.5912 - accuracy: 0.1200 - precision: 0.5714 - recall: 0.01 - ETA: 45:08 - loss: 4.5904 - accuracy: 0.1178 - precision: 0.5714 - recall: 0.00 - ETA: 44:46 - loss: 4.6049 - accuracy: 0.1134 - precision: 0.5714 - recall: 0.00 - ETA: 44:43 - loss: 4.6187 - accuracy: 0.1094 - precision: 0.5714 - recall: 0.00 - ETA: 44:30 - loss: 4.6252 - accuracy: 0.1078 - precision: 0.5714 - recall: 0.00 - ETA: 44:20 - loss: 4.6286 - accuracy: 0.1083 - precision: 0.5714 - recall: 0.00 - ETA: 44:00 - loss: 4.6167 - accuracy: 0.1129 - precision: 0.6250 - recall: 0.01 - ETA: 43:41 - loss: 4.6086 - accuracy: 0.1113 - precision: 0.6250 - recall: 0.00 - ETA: 43:22 - loss: 4.6092 - accuracy: 0.1117 - precision: 0.6250 - recall: 0.00 - ETA: 43:07 - loss: 4.5966 - accuracy: 0.1103 - precision: 0.6250 - recall: 0.00 - ETA: 42:48 - loss: 4.5745 - accuracy: 0.1143 - precision: 0.6250 - recall: 0.00 - ETA: 42:40 - loss: 4.5472 - accuracy: 0.1181 - precision: 0.6667 - recall: 0.01 - ETA: 42:23 - loss: 4.5435 - accuracy: 0.1182 - precision: 0.6667 - recall: 0.01 - ETA: 42:15 - loss: 4.5371 - accuracy: 0.1217 - precision: 0.6667 - recall: 0.00 - ETA: 42:01 - loss: 4.5285 - accuracy: 0.1250 - precision: 0.6667 - recall: 0.00 - ETA: 41:52 - loss: 4.5315 - accuracy: 0.1250 - precision: 0.6667 - recall: 0.00 - ETA: 41:41 - loss: 4.5242 - accuracy: 0.1280 - precision: 0.6667 - recall: 0.00 - ETA: 41:23 - loss: 4.5171 - accuracy: 0.1295 - precision: 0.6667 - recall: 0.00 - ETA: 41:12 - loss: 4.5011 - accuracy: 0.1308 - precision: 0.6667 - recall: 0.00 - ETA: 41:06 - loss: 4.4908 - accuracy: 0.1293 - precision: 0.6667 - recall: 0.00 - ETA: 40:54 - loss: 4.4708 - accuracy: 0.1319 - precision: 0.7000 - recall: 0.00 - ETA: 40:44 - loss: 4.4652 - accuracy: 0.1332 - precision: 0.7000 - recall: 0.00 - ETA: 40:49 - loss: 4.4596 - accuracy: 0.1343 - precision: 0.7273 - recall: 0.01 - ETA: 40:41 - loss: 4.4424 - accuracy: 0.1393 - precision: 0.6923 - recall: 0.01 - ETA: 40:28 - loss: 4.4202 - accuracy: 0.1454 - precision: 0.7647 - recall: 0.01 - ETA: 40:22 - loss: 4.4299 - accuracy: 0.1437 - precision: 0.7222 - recall: 0.01 - ETA: 40:10 - loss: 4.4246 - accuracy: 0.1434 - precision: 0.7368 - recall: 0.01 - ETA: 40:06 - loss: 4.4307 - accuracy: 0.1406 - precision: 0.6667 - recall: 0.01 - ETA: 39:57 - loss: 4.4331 - accuracy: 0.1392 - precision: 0.6667 - recall: 0.01 - ETA: 39:47 - loss: 4.4287 - accuracy: 0.1400 - precision: 0.6957 - recall: 0.01 - ETA: 39:49 - loss: 4.4380 - accuracy: 0.1375 - precision: 0.6957 - recall: 0.01 - ETA: 39:36 - loss: 4.4287 - accuracy: 0.1395 - precision: 0.7083 - recall: 0.01 - ETA: 39:26 - loss: 4.4206 - accuracy: 0.1404 - precision: 0.7200 - recall: 0.01 - ETA: 39:19 - loss: 4.4022 - accuracy: 0.1433 - precision: 0.7308 - recall: 0.02 - ETA: 39:08 - loss: 4.3942 - accuracy: 0.1430 - precision: 0.7143 - recall: 0.02 - ETA: 38:57 - loss: 4.4004 - accuracy: 0.1427 - precision: 0.6897 - recall: 0.02 - ETA: 38:49 - loss: 4.3980 - accuracy: 0.1424 - precision: 0.7000 - recall: 0.02 - ETA: 38:43 - loss: 4.3923 - accuracy: 0.1431 - precision: 0.7000 - recall: 0.02 - ETA: 38:34 - loss: 4.3867 - accuracy: 0.1438 - precision: 0.7000 - recall: 0.02 - ETA: 38:22 - loss: 4.3873 - accuracy: 0.1455 - precision: 0.7097 - recall: 0.02 - ETA: 38:28 - loss: 4.3838 - accuracy: 0.1471 - precision: 0.7188 - recall: 0.02 - ETA: 38:28 - loss: 4.3716 - accuracy: 0.1496 - precision: 0.7353 - recall: 0.02 - ETA: 38:29 - loss: 4.3627 - accuracy: 0.1502 - precision: 0.7143 - recall: 0.02 - ETA: 38:21 - loss: 4.3653 - accuracy: 0.1489 - precision: 0.6944 - recall: 0.02 - ETA: 38:18 - loss: 4.3610 - accuracy: 0.1495 - precision: 0.7105 - recall: 0.02 - ETA: 38:19 - loss: 4.3456 - accuracy: 0.1527 - precision: 0.7250 - recall: 0.02 - ETA: 38:25 - loss: 4.3360 - accuracy: 0.1540 - precision: 0.7317 - recall: 0.02 - ETA: 38:24 - loss: 4.3357 - accuracy: 0.1519 - precision: 0.7317 - recall: 0.02 - ETA: 38:21 - loss: 4.3314 - accuracy: 0.1515 - precision: 0.7442 - recall: 0.02 - ETA: 38:22 - loss: 4.3205 - accuracy: 0.1529 - precision: 0.7500 - recall: 0.02 - ETA: 38:11 - loss: 4.3182 - accuracy: 0.1533 - precision: 0.7556 - recall: 0.02 - ETA: 38:20 - loss: 4.3204 - accuracy: 0.1530 - precision: 0.7556 - recall: 0.02 - ETA: 38:30 - loss: 4.3241 - accuracy: 0.1526 - precision: 0.7609 - recall: 0.02 - ETA: 38:25 - loss: 4.3252 - accuracy: 0.1522 - precision: 0.7447 - recall: 0.02 - ETA: 38:26 - loss: 4.3230 - accuracy: 0.1519 - precision: 0.7447 - recall: 0.02 - ETA: 38:20 - loss: 4.3176 - accuracy: 0.1531 - precision: 0.7447 - recall: 0.02 - ETA: 38:13 - loss: 4.3136 - accuracy: 0.1535 - precision: 0.7500 - recall: 0.02 - ETA: 38:09 - loss: 4.3099 - accuracy: 0.1547 - precision: 0.7551 - recall: 0.02 - ETA: 38:03 - loss: 4.3143 - accuracy: 0.1536 - precision: 0.7400 - recall: 0.02 - ETA: 37:55 - loss: 4.3120 - accuracy: 0.1525 - precision: 0.7451 - recall: 0.02 - ETA: 37:53 - loss: 4.3031 - accuracy: 0.1529 - precision: 0.7500 - recall: 0.02 - ETA: 37:50 - loss: 4.2979 - accuracy: 0.1533 - precision: 0.7593 - recall: 0.02 - ETA: 37:45 - loss: 4.2966 - accuracy: 0.1537 - precision: 0.7636 - recall: 0.03 - ETA: 37:39 - loss: 4.2993 - accuracy: 0.1541 - precision: 0.7636 - recall: 0.02 - ETA: 37:33 - loss: 4.2916 - accuracy: 0.1545 - precision: 0.7544 - recall: 0.03 - ETA: 37:25 - loss: 4.2881 - accuracy: 0.1542 - precision: 0.7586 - recall: 0.03 - ETA: 37:19 - loss: 4.2848 - accuracy: 0.1552 - precision: 0.7627 - recall: 0.03 - ETA: 37:14 - loss: 4.2805 - accuracy: 0.1569 - precision: 0.7541 - recall: 0.03 - ETA: 37:09 - loss: 4.2849 - accuracy: 0.1559 - precision: 0.7541 - recall: 0.03 - ETA: 37:06 - loss: 4.2775 - accuracy: 0.1576 - precision: 0.7581 - recall: 0.03 - ETA: 37:00 - loss: 4.2817 - accuracy: 0.1579 - precision: 0.7581 - recall: 0.03 - ETA: 36:53 - loss: 4.2791 - accuracy: 0.1589 - precision: 0.7656 - recall: 0.03 - ETA: 36:51 - loss: 4.2771 - accuracy: 0.1585 - precision: 0.7656 - recall: 0.03 - ETA: 36:44 - loss: 4.2836 - accuracy: 0.1582 - precision: 0.7538 - recall: 0.03 - ETA: 36:48 - loss: 4.2828 - accuracy: 0.1578 - precision: 0.7538 - recall: 0.03 - ETA: 36:43 - loss: 4.2829 - accuracy: 0.1569 - precision: 0.7538 - recall: 0.03 - ETA: 36:46 - loss: 4.2838 - accuracy: 0.1578 - precision: 0.7463 - recall: 0.03 - ETA: 36:40 - loss: 4.2839 - accuracy: 0.1569 - precision: 0.7500 - recall: 0.03 - ETA: 36:35 - loss: 4.2859 - accuracy: 0.1566 - precision: 0.7391 - recall: 0.03 - ETA: 36:32 - loss: 4.2890 - accuracy: 0.1556 - precision: 0.7324 - recall: 0.03 - ETA: 36:28 - loss: 4.2823 - accuracy: 0.1577 - precision: 0.7260 - recall: 0.03 - ETA: 36:29 - loss: 4.2745 - accuracy: 0.1586 - precision: 0.7237 - recall: 0.03 - ETA: 36:24 - loss: 4.2705 - accuracy: 0.1595 - precision: 0.7179 - recall: 0.03 - ETA: 36:20 - loss: 4.2634 - accuracy: 0.1609 - precision: 0.7125 - recall: 0.03 - ETA: 36:18 - loss: 4.2595 - accuracy: 0.1611 - precision: 0.7125 - recall: 0.03 - ETA: 36:22 - loss: 4.2563 - accuracy: 0.1614 - precision: 0.7160 - recall: 0.03 - ETA: 36:17 - loss: 4.2506 - accuracy: 0.1622 - precision: 0.7229 - recall: 0.03 - ETA: 36:13 - loss: 4.2486 - accuracy: 0.1624 - precision: 0.7176 - recall: 0.03 - ETA: 36:10 - loss: 4.2468 - accuracy: 0.1626 - precision: 0.7209 - recall: 0.03 - ETA: 36:06 - loss: 4.2465 - accuracy: 0.1623 - precision: 0.7209 - recall: 0.03 - ETA: 36:01 - loss: 4.2459 - accuracy: 0.1620 - precision: 0.7241 - recall: 0.03 - ETA: 35:58 - loss: 4.2493 - accuracy: 0.1616 - precision: 0.7241 - recall: 0.03 - ETA: 35:56 - loss: 4.2490 - accuracy: 0.1613 - precision: 0.7273 - recall: 0.03 - ETA: 35:52 - loss: 4.2511 - accuracy: 0.1600 - precision: 0.7273 - recall: 0.03 - ETA: 35:50 - loss: 4.2556 - accuracy: 0.1591 - precision: 0.7303 - recall: 0.03 - ETA: 35:52 - loss: 4.2462 - accuracy: 0.1599 - precision: 0.7333 - recall: 0.03 - ETA: 35:57 - loss: 4.2432 - accuracy: 0.1596 - precision: 0.7333 - recall: 0.03 - ETA: 35:52 - loss: 4.2409 - accuracy: 0.1603 - precision: 0.7283 - recall: 0.03 - ETA: 35:49 - loss: 4.2354 - accuracy: 0.1611 - precision: 0.7312 - recall: 0.03 - ETA: 35:44 - loss: 4.2304 - accuracy: 0.1618 - precision: 0.7396 - recall: 0.03 - ETA: 35:39 - loss: 4.2266 - accuracy: 0.1625 - precision: 0.7396 - recall: 0.03 - ETA: 35:35 - loss: 4.2298 - accuracy: 0.1622 - precision: 0.7396 - recall: 0.03 - ETA: 35:32 - loss: 4.2349 - accuracy: 0.1614 - precision: 0.7396 - recall: 0.03 - ETA: 35:31 - loss: 4.2314 - accuracy: 0.1616 - precision: 0.7423 - recall: 0.03 - ETA: 35:29 - loss: 4.2293 - accuracy: 0.1623 - precision: 0.7449 - recall: 0.03 - ETA: 35:24 - loss: 4.2288 - accuracy: 0.1620 - precision: 0.7475 - recall: 0.03 - ETA: 35:20 - loss: 4.2234 - accuracy: 0.1632 - precision: 0.7475 - recall: 0.03 - ETA: 35:23 - loss: 4.2206 - accuracy: 0.1643 - precision: 0.7475 - recall: 0.03 - ETA: 35:24 - loss: 4.2216 - accuracy: 0.1640 - precision: 0.7327 - recall: 0.03 - ETA: 35:28 - loss: 4.2207 - accuracy: 0.1642 - precision: 0.7379 - recall: 0.03 - ETA: 35:24 - loss: 4.2238 - accuracy: 0.1630 - precision: 0.7379 - recall: 0.03 - ETA: 35:20 - loss: 4.2267 - accuracy: 0.1622 - precision: 0.7379 - recall: 0.03 - ETA: 35:16 - loss: 4.2287 - accuracy: 0.1633 - precision: 0.7308 - recall: 0.03 - ETA: 35:17 - loss: 4.2271 - accuracy: 0.1635 - precision: 0.7308 - recall: 0.03 - ETA: 35:13 - loss: 4.2314 - accuracy: 0.1628 - precision: 0.7264 - recall: 0.03 - ETA: 35:12 - loss: 4.2325 - accuracy: 0.1629 - precision: 0.7290 - recall: 0.03 - ETA: 35:07 - loss: 4.2283 - accuracy: 0.1631 - precision: 0.7315 - recall: 0.03 - ETA: 35:04 - loss: 4.2277 - accuracy: 0.1629 - precision: 0.7315 - recall: 0.03 - ETA: 35:01 - loss: 4.2289 - accuracy: 0.1617 - precision: 0.7315 - recall: 0.03 - ETA: 34:56 - loss: 4.2231 - accuracy: 0.1623 - precision: 0.7364 - recall: 0.03 - ETA: 34:52 - loss: 4.2211 - accuracy: 0.1629 - precision: 0.7364 - recall: 0.03 - ETA: 34:47 - loss: 4.2169 - accuracy: 0.1635 - precision: 0.7387 - recall: 0.03 - ETA: 34:43 - loss: 4.2175 - accuracy: 0.1633 - precision: 0.7387 - recall: 0.03 - ETA: 34:41 - loss: 4.2134 - accuracy: 0.1634 - precision: 0.7387 - recall: 0.03 - ETA: 34:42 - loss: 4.2144 - accuracy: 0.1640 - precision: 0.7387 - recall: 0.03 - ETA: 34:36 - loss: 4.2127 - accuracy: 0.1650 - precision: 0.7387 - recall: 0.03 - ETA: 34:32 - loss: 4.2120 - accuracy: 0.1647 - precision: 0.7411 - recall: 0.03 - ETA: 34:28 - loss: 4.2061 - accuracy: 0.1653 - precision: 0.7456 - recall: 0.03 - ETA: 34:23 - loss: 4.2056 - accuracy: 0.1654 - precision: 0.7478 - recall: 0.03 - ETA: 34:19 - loss: 4.2051 - accuracy: 0.1648 - precision: 0.7500 - recall: 0.03 - ETA: 34:17 - loss: 4.2036 - accuracy: 0.1645 - precision: 0.7436 - recall: 0.03 - ETA: 34:15 - loss: 4.2045 - accuracy: 0.1647 - precision: 0.7479 - recall: 0.03 - ETA: 34:12 - loss: 4.2076 - accuracy: 0.1640 - precision: 0.7417 - recall: 0.03 - ETA: 34:08 - loss: 4.2094 - accuracy: 0.1630 - precision: 0.7355 - recall: 0.03 - ETA: 34:06 - loss: 4.2055 - accuracy: 0.1631 - precision: 0.7398 - recall: 0.03 - ETA: 34:04 - loss: 4.2027 - accuracy: 0.1637 - precision: 0.7419 - recall: 0.03 - ETA: 34:00 - loss: 4.2001 - accuracy: 0.1638 - precision: 0.7440 - recall: 0.03 - ETA: 34:03 - loss: 4.1950 - accuracy: 0.1644 - precision: 0.7500 - recall: 0.03 - ETA: 33:59 - loss: 4.1918 - accuracy: 0.1645 - precision: 0.7519 - recall: 0.03 - ETA: 33:54 - loss: 4.1843 - accuracy: 0.1658 - precision: 0.7576 - recall: 0.03 - ETA: 33:50 - loss: 4.1810 - accuracy: 0.1655 - precision: 0.7594 - recall: 0.03 - ETA: 33:47 - loss: 4.1803 - accuracy: 0.1660 - precision: 0.7630 - recall: 0.03 - ETA: 33:45 - loss: 4.1766 - accuracy: 0.1669 - precision: 0.7664 - recall: 0.03 - ETA: 33:41 - loss: 4.1728 - accuracy: 0.1670 - precision: 0.7698 - recall: 0.03 - ETA: 33:38 - loss: 4.1705 - accuracy: 0.1679 - precision: 0.7714 - recall: 0.03 - ETA: 33:35 - loss: 4.1702 - accuracy: 0.1680 - precision: 0.7660 - recall: 0.03 - ETA: 33:33 - loss: 4.1743 - accuracy: 0.1674 - precision: 0.7606 - recall: 0.03 - ETA: 33:29 - loss: 4.1704 - accuracy: 0.1679 - precision: 0.7639 - recall: 0.04 - ETA: 33:28 - loss: 4.1658 - accuracy: 0.1684 - precision: 0.7671 - recall: 0.04 - ETA: 33:25 - loss: 4.1623 - accuracy: 0.1681 - precision: 0.7671 - recall: 0.04 - ETA: 33:20 - loss: 4.1601 - accuracy: 0.1689 - precision: 0.7671 - recall: 0.04 - ETA: 33:22 - loss: 4.1578 - accuracy: 0.1690 - precision: 0.7687 - recall: 0.04 - ETA: 33:18 - loss: 4.1591 - accuracy: 0.1688 - precision: 0.7687 - recall: 0.03 - ETA: 33:16 - loss: 4.1510 - accuracy: 0.1706 - precision: 0.7687 - recall: 0.03 - ETA: 33:15 - loss: 4.1496 - accuracy: 0.1707 - precision: 0.7703 - recall: 0.03 - ETA: 33:14 - loss: 4.1468 - accuracy: 0.1715 - precision: 0.7733 - recall: 0.04 - ETA: 33:11 - loss: 4.1430 - accuracy: 0.1723 - precision: 0.7763 - recall: 0.04 - ETA: 33:08 - loss: 4.1436 - accuracy: 0.1724 - precision: 0.7778 - recall: 0.04 - ETA: 33:08 - loss: 4.1389 - accuracy: 0.1728 - precision: 0.7792 - recall: 0.04 - ETA: 33:06 - loss: 4.1360 - accuracy: 0.1732 - precision: 0.7771 - recall: 0.04 - ETA: 33:02 - loss: 4.1334 - accuracy: 0.1736 - precision: 0.7799 - recall: 0.04 - ETA: 32:58 - loss: 4.1309 - accuracy: 0.1744 - precision: 0.7812 - recall: 0.04 - ETA: 32:55 - loss: 4.1285 - accuracy: 0.1745 - precision: 0.7826 - recall: 0.04 - ETA: 32:53 - loss: 4.1273 - accuracy: 0.1745 - precision: 0.7853 - recall: 0.04 - ETA: 32:51 - loss: 4.1229 - accuracy: 0.1746 - precision: 0.7879 - recall: 0.04 - ETA: 32:50 - loss: 4.1257 - accuracy: 0.1743 - precision: 0.7892 - recall: 0.04 - ETA: 32:47 - loss: 4.1239 - accuracy: 0.1744 - precision: 0.7917 - recall: 0.04 - ETA: 32:46 - loss: 4.1197 - accuracy: 0.1748 - precision: 0.7953 - recall: 0.04 - ETA: 32:45 - loss: 4.1189 - accuracy: 0.1752 - precision: 0.7977 - recall: 0.04 - ETA: 32:42 - loss: 4.1188 - accuracy: 0.1753 - precision: 0.8000 - recall: 0.04 - ETA: 32:39 - loss: 4.1145 - accuracy: 0.1756 - precision: 0.8045 - recall: 0.04 - ETA: 32:36 - loss: 4.1074 - accuracy: 0.1767 - precision: 0.8066 - recall: 0.04 - ETA: 32:35 - loss: 4.1133 - accuracy: 0.1758 - precision: 0.7978 - recall: 0.04 - ETA: 32:31 - loss: 4.1109 - accuracy: 0.1765 - precision: 0.7989 - recall: 0.04 - ETA: 32:28 - loss: 4.1098 - accuracy: 0.1771 - precision: 0.8011 - recall: 0.04 - ETA: 32:24 - loss: 4.1074 - accuracy: 0.1781 - precision: 0.8042 - recall: 0.04 - ETA: 32:21 - loss: 4.1064 - accuracy: 0.1782 - precision: 0.8063 - recall: 0.04 - ETA: 32:21 - loss: 4.1034 - accuracy: 0.1785 - precision: 0.8031 - recall: 0.04 - ETA: 32:18 - loss: 4.0986 - accuracy: 0.1792 - precision: 0.8061 - recall: 0.04 - ETA: 32:15 - loss: 4.0969 - accuracy: 0.1792 - precision: 0.8020 - recall: 0.04 - ETA: 32:15 - loss: 4.0975 - accuracy: 0.1796 - precision: 0.8030 - recall: 0.04 - ETA: 32:14 - loss: 4.0936 - accuracy: 0.1802 - precision: 0.8020 - recall: 0.04 - ETA: 32:13 - loss: 4.0927 - accuracy: 0.1803 - precision: 0.7990 - recall: 0.04 - ETA: 32:09 - loss: 4.0962 - accuracy: 0.1800 - precision: 0.7885 - recall: 0.04 - ETA: 32:07 - loss: 4.0962 - accuracy: 0.1794 - precision: 0.7857 - recall: 0.04 - ETA: 32:05 - loss: 4.0943 - accuracy: 0.1798 - precision: 0.7867 - recall: 0.04 - ETA: 32:02 - loss: 4.0942 - accuracy: 0.1798 - precision: 0.7887 - recall: 0.04 - ETA: 32:02 - loss: 4.0856 - accuracy: 0.1819 - precision: 0.7926 - recall: 0.05 - ETA: 32:01 - loss: 4.0863 - accuracy: 0.1819 - precision: 0.7854 - recall: 0.05 - ETA: 31:58 - loss: 4.0840 - accuracy: 0.1814 - precision: 0.7864 - recall: 0.05 - ETA: 31:56 - loss: 4.0826 - accuracy: 0.1817 - precision: 0.7838 - recall: 0.05 - ETA: 31:54 - loss: 4.0871 - accuracy: 0.1811 - precision: 0.7768 - recall: 0.05 - ETA: 31:52 - loss: 4.0854 - accuracy: 0.1809 - precision: 0.7788 - recall: 0.05 - ETA: 31:52 - loss: 4.0823 - accuracy: 0.1809 - precision: 0.7797 - recall: 0.05 - ETA: 31:50 - loss: 4.0817 - accuracy: 0.1807 - precision: 0.7773 - recall: 0.05 - ETA: 31:48 - loss: 4.0775 - accuracy: 0.1815 - precision: 0.7802 - recall: 0.05 - ETA: 31:45 - loss: 4.0758 - accuracy: 0.1816 - precision: 0.7778 - recall: 0.05 - ETA: 31:42 - loss: 4.0766 - accuracy: 0.1813 - precision: 0.7787 - recall: 0.05 - ETA: 31:41 - loss: 4.0733 - accuracy: 0.1819 - precision: 0.7787 - recall: 0.05 - ETA: 31:38 - loss: 4.0751 - accuracy: 0.1819 - precision: 0.7797 - recall: 0.05 - ETA: 31:36 - loss: 4.0763 - accuracy: 0.1817 - precision: 0.7764 - recall: 0.05 - ETA: 31:32 - loss: 4.0782 - accuracy: 0.1817 - precision: 0.7741 - recall: 0.05 - ETA: 31:29 - loss: 4.0794 - accuracy: 0.1812 - precision: 0.7750 - recall: 0.05 - ETA: 31:28 - loss: 4.0783 - accuracy: 0.1809 - precision: 0.7759 - recall: 0.05 - ETA: 31:25 - loss: 4.0801 - accuracy: 0.1809 - precision: 0.7759 - recall: 0.05 - ETA: 31:23 - loss: 4.0773 - accuracy: 0.1813 - precision: 0.7769 - recall: 0.05 - ETA: 31:22 - loss: 4.0753 - accuracy: 0.1815 - precision: 0.7769 - recall: 0.05 - ETA: 31:19 - loss: 4.0735 - accuracy: 0.1821 - precision: 0.7769 - recall: 0.05 - ETA: 31:16 - loss: 4.0709 - accuracy: 0.1827 - precision: 0.7787 - recall: 0.05 - ETA: 31:14 - loss: 4.0682 - accuracy: 0.1832 - precision: 0.7823 - recall: 0.05 - ETA: 31:13 - loss: 4.0666 - accuracy: 0.1835 - precision: 0.7840 - recall: 0.05 - ETA: 31:14 - loss: 4.0677 - accuracy: 0.1830 - precision: 0.7840 - recall: 0.05 - ETA: 31:13 - loss: 4.0659 - accuracy: 0.1833 - precision: 0.7826 - recall: 0.05 - ETA: 31:12 - loss: 4.0664 - accuracy: 0.1830 - precision: 0.7835 - recall: 0.05 - ETA: 31:08 - loss: 4.0690 - accuracy: 0.1828 - precision: 0.7812 - recall: 0.05 - ETA: 31:07 - loss: 4.0667 - accuracy: 0.1833 - precision: 0.7829 - recall: 0.05 - ETA: 31:05 - loss: 4.0668 - accuracy: 0.1834 - precision: 0.7799 - recall: 0.05 - ETA: 31:02 - loss: 4.0673 - accuracy: 0.1836 - precision: 0.7786 - recall: 0.05 - ETA: 31:00 - loss: 4.0642 - accuracy: 0.1844 - precision: 0.7727 - recall: 0.05 - ETA: 30:57 - loss: 4.0634 - accuracy: 0.1847 - precision: 0.7744 - recall: 0.05 - ETA: 30:54 - loss: 4.0617 - accuracy: 0.1847 - precision: 0.7715 - recall: 0.05 - ETA: 30:53 - loss: 4.0592 - accuracy: 0.1847 - precision: 0.7741 - recall: 0.05 - ETA: 30:55 - loss: 4.0582 - accuracy: 0.1845 - precision: 0.7741 - recall: 0.05 - ETA: 30:52 - loss: 4.0578 - accuracy: 0.1842 - precision: 0.7712 - recall: 0.05 - ETA: 30:50 - loss: 4.0535 - accuracy: 0.1855 - precision: 0.7721 - recall: 0.05 - ETA: 30:47 - loss: 4.0492 - accuracy: 0.1863 - precision: 0.7729 - recall: 0.05 - ETA: 30:44 - loss: 4.0501 - accuracy: 0.1858 - precision: 0.7701 - recall: 0.05 - ETA: 30:41 - loss: 4.0495 - accuracy: 0.1860 - precision: 0.7701 - recall: 0.05 - ETA: 30:38 - loss: 4.0497 - accuracy: 0.1860 - precision: 0.7717 - recall: 0.05 - ETA: 30:36 - loss: 4.0448 - accuracy: 0.1870 - precision: 0.7726 - recall: 0.05 - ETA: 30:33 - loss: 4.0425 - accuracy: 0.1870 - precision: 0.7734 - recall: 0.05 - ETA: 30:35 - loss: 4.0397 - accuracy: 0.1870 - precision: 0.7750 - recall: 0.05 - ETA: 30:34 - loss: 4.0370 - accuracy: 0.1873 - precision: 0.7739 - recall: 0.05 - ETA: 30:36 - loss: 4.0343 - accuracy: 0.1873 - precision: 0.7711 - recall: 0.05 - ETA: 30:33 - loss: 4.0334 - accuracy: 0.1873 - precision: 0.7700 - recall: 0.05 - ETA: 30:31 - loss: 4.0326 - accuracy: 0.1873 - precision: 0.7682 - recall: 0.05 - ETA: 30:28 - loss: 4.0311 - accuracy: 0.1877 - precision: 0.7698 - recall: 0.05 - ETA: 30:26 - loss: 4.0293 - accuracy: 0.1882 - precision: 0.7705 - recall: 0.05 - ETA: 30:23 - loss: 4.0298 - accuracy: 0.1885 - precision: 0.7679 - recall: 0.05 - ETA: 30:23 - loss: 4.0300 - accuracy: 0.1887 - precision: 0.7695 - recall: 0.05 - ETA: 30:21 - loss: 4.0251 - accuracy: 0.1894 - precision: 0.7718 - recall: 0.05 - ETA: 30:18 - loss: 4.0225 - accuracy: 0.1898 - precision: 0.7708 - recall: 0.05 - ETA: 30:15 - loss: 4.0210 - accuracy: 0.1896 - precision: 0.7690 - recall: 0.05 - ETA: 30:14 - loss: 4.0214 - accuracy: 0.1894 - precision: 0.7647 - recall: 0.05 - ETA: 30:11 - loss: 4.0247 - accuracy: 0.1889 - precision: 0.7622 - recall: 0.05 - ETA: 30:09 - loss: 4.0240 - accuracy: 0.1889 - precision: 0.7638 - recall: 0.05 - ETA: 30:07 - loss: 4.0230 - accuracy: 0.1889 - precision: 0.7636 - recall: 0.05 - ETA: 30:04 - loss: 4.0210 - accuracy: 0.1891 - precision: 0.7627 - recall: 0.05 - ETA: 30:01 - loss: 4.0190 - accuracy: 0.1893 - precision: 0.7634 - recall: 0.05 - ETA: 29:57 - loss: 4.0174 - accuracy: 0.1896 - precision: 0.7625 - recall: 0.05 - ETA: 29:56 - loss: 4.0172 - accuracy: 0.1900 - precision: 0.7647 - recall: 0.05 - ETA: 29:53 - loss: 4.0186 - accuracy: 0.1900 - precision: 0.7623 - recall: 0.05 - ETA: 29:53 - loss: 4.0188 - accuracy: 0.1900 - precision: 0.7600 - recall: 0.05 - ETA: 29:51 - loss: 4.0178 - accuracy: 0.1902 - precision: 0.7591 - recall: 0.05 - ETA: 29:49 - loss: 4.0166 - accuracy: 0.1904 - precision: 0.7560 - recall: 0.05 - ETA: 29:46 - loss: 4.0142 - accuracy: 0.1911 - precision: 0.7552 - recall: 0.05 - ETA: 29:46 - loss: 4.0129 - accuracy: 0.1917 - precision: 0.7567 - recall: 0.05 - ETA: 29:43 - loss: 4.0119 - accuracy: 0.1922 - precision: 0.7552 - recall: 0.05 - ETA: 29:40 - loss: 4.0100 - accuracy: 0.1924 - precision: 0.7573 - recall: 0.05 - ETA: 29:38 - loss: 4.0077 - accuracy: 0.1928 - precision: 0.7587 - recall: 0.05 - ETA: 29:36 - loss: 4.0098 - accuracy: 0.1921 - precision: 0.7587 - recall: 0.05 - ETA: 29:33 - loss: 4.0088 - accuracy: 0.1925 - precision: 0.7608 - recall: 0.05 - ETA: 29:31 - loss: 4.0063 - accuracy: 0.1932 - precision: 0.7622 - recall: 0.05 - ETA: 29:28 - loss: 4.0029 - accuracy: 0.1938 - precision: 0.7629 - recall: 0.05 - ETA: 29:25 - loss: 3.9998 - accuracy: 0.1944 - precision: 0.7635 - recall: 0.05 - ETA: 29:22 - loss: 3.9990 - accuracy: 0.1948 - precision: 0.7649 - recall: 0.05 - ETA: 29:20 - loss: 3.9968 - accuracy: 0.1954 - precision: 0.7640 - recall: 0.05 - ETA: 29:19 - loss: 3.9951 - accuracy: 0.1961 - precision: 0.7626 - recall: 0.05 - ETA: 29:16 - loss: 3.9960 - accuracy: 0.1956 - precision: 0.7590 - recall: 0.05 - ETA: 29:14 - loss: 3.9950 - accuracy: 0.1960 - precision: 0.7582 - recall: 0.05 - ETA: 29:11 - loss: 3.9940 - accuracy: 0.1958 - precision: 0.7596 - recall: 0.05 - ETA: 29:10 - loss: 3.9913 - accuracy: 0.1962 - precision: 0.7596 - recall: 0.05 - ETA: 29:09 - loss: 3.9895 - accuracy: 0.1965 - precision: 0.7601 - recall: 0.05 - ETA: 29:06 - loss: 3.9892 - accuracy: 0.1963 - precision: 0.7608 - recall: 0.05 - ETA: 29:03 - loss: 3.9886 - accuracy: 0.1965 - precision: 0.7620 - recall: 0.05 - ETA: 29:02 - loss: 3.9867 - accuracy: 0.1969 - precision: 0.7639 - recall: 0.06 - ETA: 29:02 - loss: 3.9856 - accuracy: 0.1973 - precision: 0.7638 - recall: 0.06 - ETA: 29:03 - loss: 3.9858 - accuracy: 0.1970 - precision: 0.7610 - recall: 0.06 - ETA: 29:01 - loss: 3.9845 - accuracy: 0.1974 - precision: 0.7623 - recall: 0.06 - ETA: 28:59 - loss: 3.9821 - accuracy: 0.1978 - precision: 0.7635 - recall: 0.06 - ETA: 28:57 - loss: 3.9790 - accuracy: 0.1982 - precision: 0.7647 - recall: 0.06 - ETA: 28:54 - loss: 3.9769 - accuracy: 0.1985 - precision: 0.7653 - recall: 0.06 - ETA: 28:51 - loss: 3.9770 - accuracy: 0.1983 - precision: 0.7653 - recall: 0.06 - ETA: 28:49 - loss: 3.9759 - accuracy: 0.1983 - precision: 0.7653 - recall: 0.06 - ETA: 28:47 - loss: 3.9731 - accuracy: 0.1988 - precision: 0.7659 - recall: 0.06 - ETA: 28:44 - loss: 3.9704 - accuracy: 0.1994 - precision: 0.7652 - recall: 0.06 - ETA: 28:42 - loss: 3.9676 - accuracy: 0.1998 - precision: 0.7632 - recall: 0.06 - ETA: 28:39 - loss: 3.9653 - accuracy: 0.2001 - precision: 0.7638 - recall: 0.06 - ETA: 28:38 - loss: 3.9664 - accuracy: 0.2001 - precision: 0.7644 - recall: 0.06 - ETA: 28:35 - loss: 3.9655 - accuracy: 0.2004 - precision: 0.7612 - recall: 0.06 - ETA: 28:33 - loss: 3.9632 - accuracy: 0.2008 - precision: 0.7605 - recall: 0.06 - ETA: 28:31 - loss: 3.9613 - accuracy: 0.2009 - precision: 0.7617 - recall: 0.06 - ETA: 28:29 - loss: 3.9620 - accuracy: 0.2007 - precision: 0.7604 - recall: 0.06 - ETA: 28:27 - loss: 3.9616 - accuracy: 0.2011 - precision: 0.7603 - recall: 0.06 - ETA: 28:26 - loss: 3.9612 - accuracy: 0.2010 - precision: 0.7596 - recall: 0.06 - ETA: 28:25 - loss: 3.9607 - accuracy: 0.2006 - precision: 0.7542 - recall: 0.06 - ETA: 28:23 - loss: 3.9587 - accuracy: 0.2013 - precision: 0.7530 - recall: 0.06 - ETA: 28:21 - loss: 3.9576 - accuracy: 0.2015 - precision: 0.7536 - recall: 0.06 - ETA: 28:19 - loss: 3.9558 - accuracy: 0.2016 - precision: 0.7524 - recall: 0.06 - ETA: 28:17 - loss: 3.9556 - accuracy: 0.2016 - precision: 0.7529 - recall: 0.06 - ETA: 28:15 - loss: 3.9575 - accuracy: 0.2013 - precision: 0.7535 - recall: 0.06 - ETA: 28:12 - loss: 3.9559 - accuracy: 0.2017 - precision: 0.7547 - recall: 0.06 - ETA: 28:09 - loss: 3.9558 - accuracy: 0.2020 - precision: 0.7558 - recall: 0.06 - ETA: 28:06 - loss: 3.9545 - accuracy: 0.2026 - precision: 0.7564 - recall: 0.06 - ETA: 28:07 - loss: 3.9519 - accuracy: 0.2029 - precision: 0.7575 - recall: 0.06 - ETA: 28:04 - loss: 3.9498 - accuracy: 0.2032 - precision: 0.7586 - recall: 0.06 - ETA: 28:03 - loss: 3.9488 - accuracy: 0.2037 - precision: 0.7597 - recall: 0.06 - ETA: 28:00 - loss: 3.9454 - accuracy: 0.2043 - precision: 0.7624 - recall: 0.06 - ETA: 27:58 - loss: 3.9420 - accuracy: 0.2048 - precision: 0.7606 - recall: 0.06 - ETA: 27:55 - loss: 3.9387 - accuracy: 0.2051 - precision: 0.7617 - recall: 0.06 - ETA: 27:53 - loss: 3.9374 - accuracy: 0.2050 - precision: 0.7616 - recall: 0.06 - ETA: 27:51 - loss: 3.9349 - accuracy: 0.2054 - precision: 0.7626 - recall: 0.06 - ETA: 27:50 - loss: 3.9333 - accuracy: 0.2055 - precision: 0.7632 - recall: 0.06 - ETA: 27:49 - loss: 3.9319 - accuracy: 0.2060 - precision: 0.7642 - recall: 0.06 - ETA: 27:46 - loss: 3.9314 - accuracy: 0.2059 - precision: 0.7636 - recall: 0.06 - ETA: 27:44 - loss: 3.9314 - accuracy: 0.2059 - precision: 0.7619 - recall: 0.06 - ETA: 27:42 - loss: 3.9313 - accuracy: 0.2056 - precision: 0.7597 - recall: 0.06 - ETA: 27:40 - loss: 3.9309 - accuracy: 0.2058 - precision: 0.7607 - recall: 0.06 - ETA: 27:38 - loss: 3.9282 - accuracy: 0.2068 - precision: 0.7617 - recall: 0.06 - ETA: 27:38 - loss: 3.9260 - accuracy: 0.2071 - precision: 0.7611 - recall: 0.06 - ETA: 27:36 - loss: 3.9243 - accuracy: 0.2072 - precision: 0.7605 - recall: 0.06 - ETA: 27:36 - loss: 3.9207 - accuracy: 0.2077 - precision: 0.7599 - recall: 0.06 - ETA: 27:34 - loss: 3.9181 - accuracy: 0.2075 - precision: 0.7588 - recall: 0.06 - ETA: 27:32 - loss: 3.9189 - accuracy: 0.2076 - precision: 0.7578 - recall: 0.06 - ETA: 27:29 - loss: 3.9149 - accuracy: 0.2079 - precision: 0.7598 - recall: 0.06 - ETA: 27:28 - loss: 3.9132 - accuracy: 0.2084 - precision: 0.7587 - recall: 0.06 - ETA: 27:27 - loss: 3.9121 - accuracy: 0.2085 - precision: 0.7602 - recall: 0.06 - ETA: 27:24 - loss: 3.9111 - accuracy: 0.2088 - precision: 0.7596 - recall: 0.06 - ETA: 27:21 - loss: 3.9097 - accuracy: 0.2089 - precision: 0.7590 - recall: 0.06 - ETA: 27:20 - loss: 3.9078 - accuracy: 0.2092 - precision: 0.7585 - recall: 0.06 - ETA: 27:18 - loss: 3.9078 - accuracy: 0.2090 - precision: 0.7594 - recall: 0.06 - ETA: 27:15 - loss: 3.9063 - accuracy: 0.2094 - precision: 0.7609 - recall: 0.06 - ETA: 27:17 - loss: 3.9074 - accuracy: 0.2096 - precision: 0.7569 - recall: 0.06 - ETA: 27:18 - loss: 3.9076 - accuracy: 0.2095 - precision: 0.7529 - recall: 0.06 - ETA: 27:18 - loss: 3.9067 - accuracy: 0.2094 - precision: 0.7529 - recall: 0.06 - ETA: 27:15 - loss: 3.9046 - accuracy: 0.2097 - precision: 0.7538 - recall: 0.06 - ETA: 27:13 - loss: 3.9026 - accuracy: 0.2097 - precision: 0.7505 - recall: 0.06 - ETA: 27:10 - loss: 3.9028 - accuracy: 0.2096 - precision: 0.7505 - recall: 0.06 - ETA: 27:08 - loss: 3.8993 - accuracy: 0.2101 - precision: 0.7491 - recall: 0.06 - ETA: 27:05 - loss: 3.8991 - accuracy: 0.2100 - precision: 0.7481 - recall: 0.06 - ETA: 27:03 - loss: 3.8986 - accuracy: 0.2099 - precision: 0.7481 - recall: 0.06 - ETA: 27:01 - loss: 3.8981 - accuracy: 0.2099 - precision: 0.7472 - recall: 0.06 - ETA: 26:58 - loss: 3.8970 - accuracy: 0.2103 - precision: 0.7459 - recall: 0.06 - ETA: 26:56 - loss: 3.8968 - accuracy: 0.2101 - precision: 0.7450 - recall: 0.06 - ETA: 26:54 - loss: 3.8968 - accuracy: 0.2100 - precision: 0.7441 - recall: 0.06 - ETA: 26:52 - loss: 3.8961 - accuracy: 0.2098 - precision: 0.7436 - recall: 0.06 - ETA: 26:49 - loss: 3.8966 - accuracy: 0.2097 - precision: 0.7409 - recall: 0.06 - ETA: 26:46 - loss: 3.8957 - accuracy: 0.2098 - precision: 0.7414 - recall: 0.06 - ETA: 26:47 - loss: 3.8937 - accuracy: 0.2101 - precision: 0.7433 - recall: 0.06 - ETA: 26:45 - loss: 3.8968 - accuracy: 0.2097 - precision: 0.7411 - recall: 0.06 - ETA: 26:44 - loss: 3.8964 - accuracy: 0.2098 - precision: 0.7407 - recall: 0.06 - ETA: 26:41 - loss: 3.8944 - accuracy: 0.2101 - precision: 0.7403 - recall: 0.06 - ETA: 26:40 - loss: 3.8929 - accuracy: 0.2105 - precision: 0.7407 - recall: 0.06 - ETA: 26:37 - loss: 3.8922 - accuracy: 0.2106 - precision: 0.7426 - recall: 0.07 - ETA: 26:36 - loss: 3.8927 - accuracy: 0.2106 - precision: 0.7430 - recall: 0.07 - ETA: 26:35 - loss: 3.8908 - accuracy: 0.2112 - precision: 0.7443 - recall: 0.07 - ETA: 26:33 - loss: 3.8913 - accuracy: 0.2111 - precision: 0.7448 - recall: 0.07 - ETA: 26:31 - loss: 3.8918 - accuracy: 0.2112 - precision: 0.7435 - recall: 0.07 - ETA: 26:29 - loss: 3.8892 - accuracy: 0.2121 - precision: 0.7440 - recall: 0.07 - ETA: 26:27 - loss: 3.8865 - accuracy: 0.2127 - precision: 0.7462 - recall: 0.07 - ETA: 26:25 - loss: 3.8850 - accuracy: 0.2130 - precision: 0.7470 - recall: 0.07 - ETA: 26:23 - loss: 3.8861 - accuracy: 0.2126 - precision: 0.7475 - recall: 0.07 - ETA: 26:21 - loss: 3.8851 - accuracy: 0.2125 - precision: 0.7466 - recall: 0.07 - ETA: 26:20 - loss: 3.8839 - accuracy: 0.2126 - precision: 0.7479 - recall: 0.07 - ETA: 26:17 - loss: 3.8835 - accuracy: 0.2126 - precision: 0.7479 - recall: 0.07 - ETA: 26:15 - loss: 3.8833 - accuracy: 0.2123 - precision: 0.7483 - recall: 0.07 - ETA: 26:13 - loss: 3.8835 - accuracy: 0.2123 - precision: 0.7475 - recall: 0.07 - ETA: 26:11 - loss: 3.8825 - accuracy: 0.2125 - precision: 0.7479 - recall: 0.07 - ETA: 26:09 - loss: 3.8816 - accuracy: 0.2126 - precision: 0.7483 - recall: 0.07 - ETA: 26:10 - loss: 3.8811 - accuracy: 0.2127 - precision: 0.7492 - recall: 0.07 - ETA: 26:09 - loss: 3.8792 - accuracy: 0.2130 - precision: 0.7508 - recall: 0.07 - ETA: 26:08 - loss: 3.8768 - accuracy: 0.2134 - precision: 0.7520 - recall: 0.07 - ETA: 26:06 - loss: 3.8773 - accuracy: 0.2135 - precision: 0.7508 - recall: 0.07 - ETA: 26:05 - loss: 3.8759 - accuracy: 0.2137 - precision: 0.7512 - recall: 0.07 - ETA: 26:04 - loss: 3.8743 - accuracy: 0.2140 - precision: 0.7512 - recall: 0.07 - ETA: 26:03 - loss: 3.8737 - accuracy: 0.2141 - precision: 0.7516 - recall: 0.07 - ETA: 26:00 - loss: 3.8726 - accuracy: 0.2143 - precision: 0.7520 - recall: 0.07 - ETA: 25:59 - loss: 3.8697 - accuracy: 0.2147 - precision: 0.7536 - recall: 0.07 - ETA: 25:56 - loss: 3.8686 - accuracy: 0.2148 - precision: 0.7536 - recall: 0.07 - ETA: 25:54 - loss: 3.8675 - accuracy: 0.2150 - precision: 0.7544 - recall: 0.07 - ETA: 25:54 - loss: 3.8679 - accuracy: 0.2150 - precision: 0.7552 - recall: 0.07 - ETA: 25:51 - loss: 3.8650 - accuracy: 0.2155 - precision: 0.7563 - recall: 0.07 - ETA: 25:49 - loss: 3.8627 - accuracy: 0.2159 - precision: 0.7582 - recall: 0.07 - ETA: 25:46 - loss: 3.8611 - accuracy: 0.2161 - precision: 0.7586 - recall: 0.07 - ETA: 25:44 - loss: 3.8607 - accuracy: 0.2161 - precision: 0.7578 - recall: 0.07 - ETA: 25:41 - loss: 3.8600 - accuracy: 0.2162 - precision: 0.7582 - recall: 0.07 - ETA: 25:38 - loss: 3.8609 - accuracy: 0.2159 - precision: 0.7589 - recall: 0.07 - ETA: 25:36 - loss: 3.8623 - accuracy: 0.2154 - precision: 0.7578 - recall: 0.07 - ETA: 25:34 - loss: 3.8606 - accuracy: 0.2160 - precision: 0.7577 - recall: 0.07 - ETA: 25:32 - loss: 3.8604 - accuracy: 0.2159 - precision: 0.7585 - recall: 0.07 - ETA: 25:31 - loss: 3.8609 - accuracy: 0.2158 - precision: 0.7588 - recall: 0.07 - ETA: 25:29 - loss: 3.8611 - accuracy: 0.2157 - precision: 0.7596 - recall: 0.07 - ETA: 25:27 - loss: 3.8599 - accuracy: 0.2158 - precision: 0.7599 - recall: 0.07 - ETA: 25:25 - loss: 3.8575 - accuracy: 0.2165 - precision: 0.7610 - recall: 0.07 - ETA: 25:23 - loss: 3.8574 - accuracy: 0.2166 - precision: 0.7602 - recall: 0.07 - ETA: 25:20 - loss: 3.8558 - accuracy: 0.2170 - precision: 0.7617 - recall: 0.07 - ETA: 25:18 - loss: 3.8545 - accuracy: 0.2170 - precision: 0.7609 - recall: 0.07 - ETA: 25:15 - loss: 3.8531 - accuracy: 0.2173 - precision: 0.7620 - recall: 0.07 - ETA: 25:13 - loss: 3.8530 - accuracy: 0.2172 - precision: 0.7627 - recall: 0.07 - ETA: 25:11 - loss: 3.8521 - accuracy: 0.2174 - precision: 0.7630 - recall: 0.07 - ETA: 25:09 - loss: 3.8510 - accuracy: 0.2176 - precision: 0.7637 - recall: 0.07 - ETA: 25:06 - loss: 3.8530 - accuracy: 0.2173 - precision: 0.7630 - recall: 0.07 - ETA: 25:05 - loss: 3.8516 - accuracy: 0.2174 - precision: 0.7633 - recall: 0.07 - ETA: 25:03 - loss: 3.8498 - accuracy: 0.2171 - precision: 0.7640 - recall: 0.07 - ETA: 25:00 - loss: 3.8489 - accuracy: 0.2171 - precision: 0.7636 - recall: 0.07 - ETA: 24:58 - loss: 3.8469 - accuracy: 0.2174 - precision: 0.7632 - recall: 0.07 - ETA: 24:55 - loss: 3.8450 - accuracy: 0.2177 - precision: 0.7631 - recall: 0.07 - ETA: 24:53 - loss: 3.8448 - accuracy: 0.2176 - precision: 0.7627 - recall: 0.07 - ETA: 24:50 - loss: 3.8433 - accuracy: 0.2177 - precision: 0.7637 - recall: 0.07 - ETA: 24:48 - loss: 3.8404 - accuracy: 0.2180 - precision: 0.7647 - recall: 0.07 - ETA: 24:46 - loss: 3.8391 - accuracy: 0.2182 - precision: 0.7643 - recall: 0.07 - ETA: 24:44 - loss: 3.8370 - accuracy: 0.2186 - precision: 0.7656 - recall: 0.07 - ETA: 24:43 - loss: 3.8356 - accuracy: 0.2185 - precision: 0.7663 - recall: 0.07 - ETA: 24:42 - loss: 3.8351 - accuracy: 0.2186 - precision: 0.7641 - recall: 0.07 - ETA: 24:39 - loss: 3.8333 - accuracy: 0.2188 - precision: 0.7654 - recall: 0.07 - ETA: 24:37 - loss: 3.8318 - accuracy: 0.2190 - precision: 0.7664 - recall: 0.07 - ETA: 24:34 - loss: 3.8295 - accuracy: 0.2194 - precision: 0.7671 - recall: 0.07 - ETA: 24:32 - loss: 3.8271 - accuracy: 0.2199 - precision: 0.7681 - recall: 0.07 - ETA: 24:33 - loss: 3.8260 - accuracy: 0.2198 - precision: 0.7684 - recall: 0.07 - ETA: 24:31 - loss: 3.8242 - accuracy: 0.2203 - precision: 0.7686 - recall: 0.07 - ETA: 24:29 - loss: 3.8250 - accuracy: 0.2202 - precision: 0.7675 - recall: 0.07 - ETA: 24:28 - loss: 3.8239 - accuracy: 0.2203 - precision: 0.7682 - recall: 0.07 - ETA: 24:25 - loss: 3.8213 - accuracy: 0.2205 - precision: 0.7694 - recall: 0.07 - ETA: 24:23 - loss: 3.8209 - accuracy: 0.2204 - precision: 0.7690 - recall: 0.07 - ETA: 24:21 - loss: 3.8192 - accuracy: 0.2206 - precision: 0.7700 - recall: 0.07 - ETA: 24:20 - loss: 3.8167 - accuracy: 0.2211 - precision: 0.7699 - recall: 0.07 - ETA: 24:17 - loss: 3.8164 - accuracy: 0.2212 - precision: 0.7681 - recall: 0.07 - ETA: 24:15 - loss: 3.8169 - accuracy: 0.2211 - precision: 0.7674 - recall: 0.07 - ETA: 24:13 - loss: 3.8167 - accuracy: 0.2210 - precision: 0.7667 - recall: 0.07 - ETA: 24:12 - loss: 3.8138 - accuracy: 0.2216 - precision: 0.7682 - recall: 0.07 - ETA: 24:11 - loss: 3.8139 - accuracy: 0.2216 - precision: 0.7682 - recall: 0.07 - ETA: 24:09 - loss: 3.8149 - accuracy: 0.2214 - precision: 0.7682 - recall: 0.07 - ETA: 24:07 - loss: 3.8136 - accuracy: 0.2214 - precision: 0.7675 - recall: 0.07 - ETA: 24:04 - loss: 3.8122 - accuracy: 0.2216 - precision: 0.7671 - recall: 0.07 - ETA: 24:02 - loss: 3.8106 - accuracy: 0.2219 - precision: 0.7670 - recall: 0.07 - ETA: 24:01 - loss: 3.8095 - accuracy: 0.2221 - precision: 0.7682 - recall: 0.08 - ETA: 23:58 - loss: 3.8088 - accuracy: 0.2225 - precision: 0.7661 - recall: 0.08 - ETA: 23:55 - loss: 3.8079 - accuracy: 0.2224 - precision: 0.7651 - recall: 0.08 - ETA: 23:53 - loss: 3.8051 - accuracy: 0.2227 - precision: 0.7634 - recall: 0.08 - ETA: 23:51 - loss: 3.8045 - accuracy: 0.2231 - precision: 0.7640 - recall: 0.08 - ETA: 23:49 - loss: 3.8027 - accuracy: 0.2235 - precision: 0.7646 - recall: 0.08 - ETA: 23:47 - loss: 3.8010 - accuracy: 0.2238 - precision: 0.7655 - recall: 0.08 - ETA: 23:44 - loss: 3.7985 - accuracy: 0.2240 - precision: 0.7667 - recall: 0.08 - ETA: 23:44 - loss: 3.7975 - accuracy: 0.2242 - precision: 0.7679 - recall: 0.08 - ETA: 23:42 - loss: 3.7956 - accuracy: 0.2245 - precision: 0.7685 - recall: 0.08 - ETA: 23:40 - loss: 3.7943 - accuracy: 0.2249 - precision: 0.7693 - recall: 0.08 - ETA: 23:38 - loss: 3.7936 - accuracy: 0.2251 - precision: 0.7687 - recall: 0.08 - ETA: 23:36 - loss: 3.7945 - accuracy: 0.2248 - precision: 0.7683 - recall: 0.08 - ETA: 23:35 - loss: 3.7931 - accuracy: 0.2252 - precision: 0.7691 - recall: 0.08 - ETA: 23:33 - loss: 3.7936 - accuracy: 0.2251 - precision: 0.7694 - recall: 0.08 - ETA: 23:31 - loss: 3.7929 - accuracy: 0.2253 - precision: 0.7690 - recall: 0.08 - ETA: 23:29 - loss: 3.7921 - accuracy: 0.2254 - precision: 0.7689 - recall: 0.08 - ETA: 23:27 - loss: 3.7899 - accuracy: 0.2259 - precision: 0.7691 - recall: 0.08 - ETA: 23:24 - loss: 3.7891 - accuracy: 0.2259 - precision: 0.7700 - recall: 0.08 - ETA: 23:22 - loss: 3.7890 - accuracy: 0.2260 - precision: 0.7693 - recall: 0.08 - ETA: 23:21 - loss: 3.7905 - accuracy: 0.2259 - precision: 0.7684 - recall: 0.08 - ETA: 23:19 - loss: 3.7893 - accuracy: 0.2260 - precision: 0.7692 - recall: 0.08 - ETA: 23:17 - loss: 3.7890 - accuracy: 0.2260 - precision: 0.7679 - recall: 0.08 - ETA: 23:14 - loss: 3.7890 - accuracy: 0.2259 - precision: 0.7673 - recall: 0.08 - ETA: 23:12 - loss: 3.7863 - accuracy: 0.2265 - precision: 0.7684 - recall: 0.08 - ETA: 23:11 - loss: 3.7853 - accuracy: 0.2268 - precision: 0.7690 - recall: 0.08 - ETA: 23:09 - loss: 3.7827 - accuracy: 0.2274 - precision: 0.7695 - recall: 0.08 - ETA: 23:08 - loss: 3.7814 - accuracy: 0.2274 - precision: 0.7689 - recall: 0.08 - ETA: 23:06 - loss: 3.7797 - accuracy: 0.2278 - precision: 0.7700 - recall: 0.08 - ETA: 23:04 - loss: 3.7794 - accuracy: 0.2279 - precision: 0.7699 - recall: 0.08 - ETA: 23:03 - loss: 3.7806 - accuracy: 0.2276 - precision: 0.7692 - recall: 0.08 - ETA: 23:01 - loss: 3.7808 - accuracy: 0.2273 - precision: 0.7683 - recall: 0.08 - ETA: 23:00 - loss: 3.7804 - accuracy: 0.2276 - precision: 0.7683 - recall: 0.08 - ETA: 22:58 - loss: 3.7786 - accuracy: 0.2281 - precision: 0.7691 - recall: 0.08 - ETA: 22:56 - loss: 3.7785 - accuracy: 0.2281 - precision: 0.7699 - recall: 0.08 - ETA: 22:54 - loss: 3.7786 - accuracy: 0.2282 - precision: 0.7701 - recall: 0.08 - ETA: 22:53 - loss: 3.7785 - accuracy: 0.2283 - precision: 0.7706 - recall: 0.08 - ETA: 22:53 - loss: 3.7777 - accuracy: 0.2285 - precision: 0.7708 - recall: 0.08 - ETA: 22:51 - loss: 3.7768 - accuracy: 0.2287 - precision: 0.7698 - recall: 0.08 - ETA: 22:49 - loss: 3.7739 - accuracy: 0.2292 - precision: 0.7706 - recall: 0.08 - ETA: 22:47 - loss: 3.7727 - accuracy: 0.2294 - precision: 0.7680 - recall: 0.08 - ETA: 22:45 - loss: 3.7716 - accuracy: 0.2295 - precision: 0.7683 - recall: 0.08 - ETA: 22:42 - loss: 3.7720 - accuracy: 0.2295 - precision: 0.7660 - recall: 0.08 - ETA: 22:40 - loss: 3.7696 - accuracy: 0.2297 - precision: 0.7659 - recall: 0.08 - ETA: 22:38 - loss: 3.7685 - accuracy: 0.2298 - precision: 0.7647 - recall: 0.08 - ETA: 22:36 - loss: 3.7677 - accuracy: 0.2300 - precision: 0.7633 - recall: 0.08 - ETA: 22:34 - loss: 3.7654 - accuracy: 0.2302 - precision: 0.7641 - recall: 0.08 - ETA: 22:32 - loss: 3.7657 - accuracy: 0.2302 - precision: 0.7646 - recall: 0.08 - ETA: 22:29 - loss: 3.7635 - accuracy: 0.2303 - precision: 0.7640 - recall: 0.08 - ETA: 22:27 - loss: 3.7635 - accuracy: 0.2301 - precision: 0.7634 - recall: 0.08 - ETA: 22:25 - loss: 3.7624 - accuracy: 0.2303 - precision: 0.7644 - recall: 0.08 - ETA: 22:23 - loss: 3.7630 - accuracy: 0.2301 - precision: 0.7620 - recall: 0.08 - ETA: 22:22 - loss: 3.7640 - accuracy: 0.2300 - precision: 0.7611 - recall: 0.08 - ETA: 22:21 - loss: 3.7636 - accuracy: 0.2301 - precision: 0.7614 - recall: 0.08 - ETA: 22:19 - loss: 3.7617 - accuracy: 0.2304 - precision: 0.7622 - recall: 0.08 - ETA: 22:16 - loss: 3.7600 - accuracy: 0.2308 - precision: 0.7629 - recall: 0.08 - ETA: 22:14 - loss: 3.7597 - accuracy: 0.2307 - precision: 0.7624 - recall: 0.08 - ETA: 22:12 - loss: 3.7590 - accuracy: 0.2308 - precision: 0.7621 - recall: 0.08 - ETA: 22:10 - loss: 3.7569 - accuracy: 0.2309 - precision: 0.7606 - recall: 0.08 - ETA: 22:08 - loss: 3.7557 - accuracy: 0.2311 - precision: 0.7611 - recall: 0.08 - ETA: 22:06 - loss: 3.7552 - accuracy: 0.2310 - precision: 0.7608 - recall: 0.08 - ETA: 22:03 - loss: 3.7551 - accuracy: 0.2309 - precision: 0.7600 - recall: 0.08 - ETA: 22:01 - loss: 3.7557 - accuracy: 0.2307 - precision: 0.7595 - recall: 0.08 - ETA: 22:00 - loss: 3.7542 - accuracy: 0.2309 - precision: 0.7597 - recall: 0.08 - ETA: 21:57 - loss: 3.7539 - accuracy: 0.2310 - precision: 0.7605 - recall: 0.08 - ETA: 21:55 - loss: 3.7518 - accuracy: 0.2313 - precision: 0.7615 - recall: 0.08 - ETA: 21:54 - loss: 3.7498 - accuracy: 0.2317 - precision: 0.7623 - recall: 0.08 - ETA: 21:51 - loss: 3.7486 - accuracy: 0.2320 - precision: 0.7627 - recall: 0.08 - ETA: 21:49 - loss: 3.7480 - accuracy: 0.2321 - precision: 0.7614 - recall: 0.08 - ETA: 21:47 - loss: 3.7475 - accuracy: 0.2323 - precision: 0.7601 - recall: 0.08 - ETA: 21:45 - loss: 3.7465 - accuracy: 0.2325 - precision: 0.7608 - recall: 0.08 - ETA: 21:43 - loss: 3.7467 - accuracy: 0.2323 - precision: 0.7611 - recall: 0.08 - ETA: 21:42 - loss: 3.7458 - accuracy: 0.2325 - precision: 0.7618 - recall: 0.08 - ETA: 21:39 - loss: 3.7454 - accuracy: 0.2324 - precision: 0.7618 - recall: 0.08 - ETA: 21:37 - loss: 3.7463 - accuracy: 0.2323 - precision: 0.7602 - recall: 0.08 - ETA: 21:34 - loss: 3.7463 - accuracy: 0.2322 - precision: 0.7597 - recall: 0.08 - ETA: 21:32 - loss: 3.7461 - accuracy: 0.2323 - precision: 0.7604 - recall: 0.08 - ETA: 21:31 - loss: 3.7440 - accuracy: 0.2327 - precision: 0.7606 - recall: 0.08 - ETA: 21:29 - loss: 3.7423 - accuracy: 0.2327 - precision: 0.7604 - recall: 0.08 - ETA: 21:27 - loss: 3.7423 - accuracy: 0.2326 - precision: 0.7598 - recall: 0.08 - ETA: 21:24 - loss: 3.7407 - accuracy: 0.2329 - precision: 0.7600 - recall: 0.08 - ETA: 21:23 - loss: 3.7390 - accuracy: 0.2332 - precision: 0.7598 - recall: 0.08 - ETA: 21:21 - loss: 3.7374 - accuracy: 0.2336 - precision: 0.7600 - recall: 0.08 - ETA: 21:19 - loss: 3.7375 - accuracy: 0.2334 - precision: 0.7604 - recall: 0.08 - ETA: 21:16 - loss: 3.7366 - accuracy: 0.2336 - precision: 0.7614 - recall: 0.08 - ETA: 21:14 - loss: 3.7358 - accuracy: 0.2335 - precision: 0.7616 - recall: 0.08 - ETA: 21:12 - loss: 3.7349 - accuracy: 0.2336 - precision: 0.7621 - recall: 0.08 - ETA: 21:09 - loss: 3.7353 - accuracy: 0.2333 - precision: 0.7608 - recall: 0.08 - ETA: 21:07 - loss: 3.7344 - accuracy: 0.2333 - precision: 0.7615 - recall: 0.08 - ETA: 21:05 - loss: 3.7342 - accuracy: 0.2333 - precision: 0.7598 - recall: 0.08 - ETA: 21:03 - loss: 3.7333 - accuracy: 0.2334 - precision: 0.7593 - recall: 0.08 - ETA: 21:01 - loss: 3.7326 - accuracy: 0.2332 - precision: 0.7595 - recall: 0.08 - ETA: 20:59 - loss: 3.7306 - accuracy: 0.2335 - precision: 0.7600 - recall: 0.08 - ETA: 20:57 - loss: 3.7294 - accuracy: 0.2340 - precision: 0.7604 - recall: 0.08 - ETA: 20:55 - loss: 3.7273 - accuracy: 0.2343 - precision: 0.7611 - recall: 0.08 - ETA: 20:53 - loss: 3.7253 - accuracy: 0.2349 - precision: 0.7625 - recall: 0.08 - ETA: 20:51 - loss: 3.7256 - accuracy: 0.2352 - precision: 0.7615 - recall: 0.08 - ETA: 20:49 - loss: 3.7248 - accuracy: 0.2352 - precision: 0.7620 - recall: 0.08 - ETA: 20:47 - loss: 3.7253 - accuracy: 0.2352 - precision: 0.7605 - recall: 0.08 - ETA: 20:45 - loss: 3.7256 - accuracy: 0.2351 - precision: 0.7602 - recall: 0.08 - ETA: 20:42 - loss: 3.7233 - accuracy: 0.2355 - precision: 0.7597 - recall: 0.08 - ETA: 20:41 - loss: 3.7216 - accuracy: 0.2360 - precision: 0.7608 - recall: 0.09 - ETA: 20:39 - loss: 3.7194 - accuracy: 0.2364 - precision: 0.7608 - recall: 0.09 - ETA: 20:37 - loss: 3.7188 - accuracy: 0.2365 - precision: 0.7615 - recall: 0.09 - ETA: 20:35 - loss: 3.7173 - accuracy: 0.2367 - precision: 0.7623 - recall: 0.09 - ETA: 20:33 - loss: 3.7176 - accuracy: 0.2369 - precision: 0.7628 - recall: 0.09 - ETA: 20:32 - loss: 3.7171 - accuracy: 0.2370 - precision: 0.7632 - recall: 0.09 - ETA: 20:30 - loss: 3.7156 - accuracy: 0.2371 - precision: 0.7630 - recall: 0.09 - ETA: 20:28 - loss: 3.7148 - accuracy: 0.2372 - precision: 0.7634 - recall: 0.09 - ETA: 20:26 - loss: 3.7146 - accuracy: 0.2374 - precision: 0.7636 - recall: 0.09 - ETA: 20:24 - loss: 3.7139 - accuracy: 0.2374 - precision: 0.7626 - recall: 0.09 - ETA: 20:23 - loss: 3.7138 - accuracy: 0.2377 - precision: 0.7628 - recall: 0.09 - ETA: 20:21 - loss: 3.7122 - accuracy: 0.2380 - precision: 0.7635 - recall: 0.09 - ETA: 20:18 - loss: 3.7103 - accuracy: 0.2383 - precision: 0.7648 - recall: 0.09 - ETA: 20:17 - loss: 3.7100 - accuracy: 0.2383 - precision: 0.7643 - recall: 0.09 - ETA: 20:14 - loss: 3.7098 - accuracy: 0.2385 - precision: 0.7642 - recall: 0.09 - ETA: 20:12 - loss: 3.7093 - accuracy: 0.2384 - precision: 0.7624 - recall: 0.09 - ETA: 20:11 - loss: 3.7096 - accuracy: 0.2383 - precision: 0.7617 - recall: 0.09 - ETA: 20:08 - loss: 3.7100 - accuracy: 0.2382 - precision: 0.7612 - recall: 0.09 - ETA: 20:06 - loss: 3.7106 - accuracy: 0.2383 - precision: 0.7610 - recall: 0.09 - ETA: 20:04 - loss: 3.7092 - accuracy: 0.2387 - precision: 0.7616 - recall: 0.09 - ETA: 20:02 - loss: 3.7082 - accuracy: 0.2387 - precision: 0.7604 - recall: 0.09 - ETA: 20:00 - loss: 3.7072 - accuracy: 0.2388 - precision: 0.7611 - recall: 0.09 - ETA: 19:58 - loss: 3.7057 - accuracy: 0.2390 - precision: 0.7608 - recall: 0.09 - ETA: 19:56 - loss: 3.7044 - accuracy: 0.2392 - precision: 0.7612 - recall: 0.09 - ETA: 19:54 - loss: 3.7026 - accuracy: 0.2393 - precision: 0.7609 - recall: 0.09 - ETA: 19:52 - loss: 3.7016 - accuracy: 0.2394 - precision: 0.7614 - recall: 0.09 - ETA: 19:50 - loss: 3.7012 - accuracy: 0.2396 - precision: 0.7618 - recall: 0.09 - ETA: 19:48 - loss: 3.6993 - accuracy: 0.2400 - precision: 0.7619 - recall: 0.09 - ETA: 19:46 - loss: 3.6966 - accuracy: 0.2407 - precision: 0.7634 - recall: 0.09 - ETA: 19:45 - loss: 3.6963 - accuracy: 0.2405 - precision: 0.7629 - recall: 0.09 - ETA: 19:42 - loss: 3.6972 - accuracy: 0.2404 - precision: 0.7627 - recall: 0.09 - ETA: 19:40 - loss: 3.6964 - accuracy: 0.2404 - precision: 0.7631 - recall: 0.09 - ETA: 19:38 - loss: 3.6957 - accuracy: 0.2407 - precision: 0.7632 - recall: 0.09 - ETA: 19:36 - loss: 3.6947 - accuracy: 0.2410 - precision: 0.7641 - recall: 0.09 - ETA: 19:34 - loss: 3.6953 - accuracy: 0.2410 - precision: 0.7643 - recall: 0.09 - ETA: 19:32 - loss: 3.6938 - accuracy: 0.2412 - precision: 0.7649 - recall: 0.09 - ETA: 19:29 - loss: 3.6932 - accuracy: 0.2413 - precision: 0.7655 - recall: 0.09 - ETA: 19:27 - loss: 3.6930 - accuracy: 0.2413 - precision: 0.7658 - recall: 0.09 - ETA: 19:26 - loss: 3.6939 - accuracy: 0.2412 - precision: 0.7654 - recall: 0.09 - ETA: 19:24 - loss: 3.6925 - accuracy: 0.2415 - precision: 0.7656 - recall: 0.09 - ETA: 19:22 - loss: 3.6916 - accuracy: 0.2416 - precision: 0.7653 - recall: 0.09 - ETA: 19:19 - loss: 3.6933 - accuracy: 0.2414 - precision: 0.7653 - recall: 0.09 - ETA: 19:18 - loss: 3.6933 - accuracy: 0.2414 - precision: 0.7649 - recall: 0.09 604/1187 [==============>.............. - ETA: 19:14 - loss: 3.6898 - accuracy: 0.2419 - precision: 0.7640 - recall: 0.09 - ETA: 19:12 - loss: 3.6899 - accuracy: 0.2417 - precision: 0.7642 - recall: 0.09 - ETA: 19:10 - loss: 3.6886 - accuracy: 0.2420 - precision: 0.7644 - recall: 0.09 - ETA: 19:08 - loss: 3.6895 - accuracy: 0.2417 - precision: 0.7637 - recall: 0.09 - ETA: 19:06 - loss: 3.6886 - accuracy: 0.2419 - precision: 0.7643 - recall: 0.09 - ETA: 19:03 - loss: 3.6883 - accuracy: 0.2421 - precision: 0.7637 - recall: 0.09 - ETA: 19:01 - loss: 3.6889 - accuracy: 0.2419 - precision: 0.7614 - recall: 0.09 - ETA: 19:00 - loss: 3.6883 - accuracy: 0.2420 - precision: 0.7611 - recall: 0.09 - ETA: 18:58 - loss: 3.6867 - accuracy: 0.2424 - precision: 0.7607 - recall: 0.09 - ETA: 18:55 - loss: 3.6855 - accuracy: 0.2425 - precision: 0.7615 - recall: 0.09 - ETA: 18:53 - loss: 3.6845 - accuracy: 0.2423 - precision: 0.7610 - recall: 0.09 - ETA: 18:52 - loss: 3.6839 - accuracy: 0.2424 - precision: 0.7610 - recall: 0.09 - ETA: 18:49 - loss: 3.6839 - accuracy: 0.2423 - precision: 0.7610 - recall: 0.09 - ETA: 18:47 - loss: 3.6824 - accuracy: 0.2424 - precision: 0.7614 - recall: 0.09 - ETA: 18:46 - loss: 3.6810 - accuracy: 0.2425 - precision: 0.7622 - recall: 0.09 - ETA: 18:44 - loss: 3.6813 - accuracy: 0.2425 - precision: 0.7624 - recall: 0.09 - ETA: 18:42 - loss: 3.6800 - accuracy: 0.2427 - precision: 0.7632 - recall: 0.09 - ETA: 18:40 - loss: 3.6789 - accuracy: 0.2430 - precision: 0.7638 - recall: 0.09 - ETA: 18:37 - loss: 3.6780 - accuracy: 0.2434 - precision: 0.7643 - recall: 0.09 - ETA: 18:35 - loss: 3.6782 - accuracy: 0.2433 - precision: 0.7639 - recall: 0.09 - ETA: 18:33 - loss: 3.6771 - accuracy: 0.2433 - precision: 0.7643 - recall: 0.09 - ETA: 18:31 - loss: 3.6772 - accuracy: 0.2433 - precision: 0.7647 - recall: 0.09 - ETA: 18:29 - loss: 3.6773 - accuracy: 0.2434 - precision: 0.7650 - recall: 0.09 - ETA: 18:27 - loss: 3.6762 - accuracy: 0.2437 - precision: 0.7654 - recall: 0.09 - ETA: 18:25 - loss: 3.6754 - accuracy: 0.2438 - precision: 0.7654 - recall: 0.09 - ETA: 18:23 - loss: 3.6744 - accuracy: 0.2439 - precision: 0.7651 - recall: 0.09 - ETA: 18:21 - loss: 3.6742 - accuracy: 0.2441 - precision: 0.7657 - recall: 0.09 - ETA: 18:19 - loss: 3.6720 - accuracy: 0.2446 - precision: 0.7662 - recall: 0.09 - ETA: 18:18 - loss: 3.6698 - accuracy: 0.2450 - precision: 0.7658 - recall: 0.09 - ETA: 18:15 - loss: 3.6686 - accuracy: 0.2453 - precision: 0.7666 - recall: 0.09 - ETA: 18:13 - loss: 3.6675 - accuracy: 0.2454 - precision: 0.7669 - recall: 0.09 - ETA: 18:12 - loss: 3.6670 - accuracy: 0.2452 - precision: 0.7665 - recall: 0.09 - ETA: 18:10 - loss: 3.6660 - accuracy: 0.2455 - precision: 0.7663 - recall: 0.09 - ETA: 18:08 - loss: 3.6641 - accuracy: 0.2459 - precision: 0.7670 - recall: 0.09 - ETA: 18:06 - loss: 3.6642 - accuracy: 0.2459 - precision: 0.7662 - recall: 0.09 - ETA: 18:04 - loss: 3.6622 - accuracy: 0.2461 - precision: 0.7671 - recall: 0.09 - ETA: 18:02 - loss: 3.6618 - accuracy: 0.2461 - precision: 0.7668 - recall: 0.09 - ETA: 18:00 - loss: 3.6612 - accuracy: 0.2461 - precision: 0.7674 - recall: 0.09 - ETA: 17:58 - loss: 3.6611 - accuracy: 0.2461 - precision: 0.7676 - recall: 0.09 - ETA: 17:56 - loss: 3.6607 - accuracy: 0.2462 - precision: 0.7673 - recall: 0.09 - ETA: 17:54 - loss: 3.6602 - accuracy: 0.2464 - precision: 0.7671 - recall: 0.09 - ETA: 17:53 - loss: 3.6598 - accuracy: 0.2464 - precision: 0.7676 - recall: 0.09 - ETA: 17:51 - loss: 3.6601 - accuracy: 0.2464 - precision: 0.7678 - recall: 0.09 - ETA: 17:49 - loss: 3.6606 - accuracy: 0.2463 - precision: 0.7676 - recall: 0.09 - ETA: 17:47 - loss: 3.6588 - accuracy: 0.2468 - precision: 0.7685 - recall: 0.09 - ETA: 17:45 - loss: 3.6591 - accuracy: 0.2468 - precision: 0.7686 - recall: 0.09 - ETA: 17:43 - loss: 3.6591 - accuracy: 0.2468 - precision: 0.7688 - recall: 0.09 - ETA: 17:41 - loss: 3.6565 - accuracy: 0.2472 - precision: 0.7693 - recall: 0.09 - ETA: 17:39 - loss: 3.6564 - accuracy: 0.2471 - precision: 0.7695 - recall: 0.09 - ETA: 17:37 - loss: 3.6556 - accuracy: 0.2474 - precision: 0.7696 - recall: 0.09 - ETA: 17:35 - loss: 3.6543 - accuracy: 0.2476 - precision: 0.7698 - recall: 0.09 - ETA: 17:32 - loss: 3.6538 - accuracy: 0.2478 - precision: 0.7703 - recall: 0.09 - ETA: 17:31 - loss: 3.6549 - accuracy: 0.2476 - precision: 0.7695 - recall: 0.09 - ETA: 17:28 - loss: 3.6543 - accuracy: 0.2474 - precision: 0.7685 - recall: 0.09 - ETA: 17:26 - loss: 3.6526 - accuracy: 0.2476 - precision: 0.7689 - recall: 0.09 - ETA: 17:25 - loss: 3.6514 - accuracy: 0.2477 - precision: 0.7681 - recall: 0.09 - ETA: 17:22 - loss: 3.6518 - accuracy: 0.2475 - precision: 0.7681 - recall: 0.09 - ETA: 17:20 - loss: 3.6516 - accuracy: 0.2475 - precision: 0.7686 - recall: 0.09 - ETA: 17:18 - loss: 3.6509 - accuracy: 0.2478 - precision: 0.7691 - recall: 0.09 - ETA: 17:16 - loss: 3.6495 - accuracy: 0.2483 - precision: 0.7696 - recall: 0.09 - ETA: 17:14 - loss: 3.6488 - accuracy: 0.2484 - precision: 0.7698 - recall: 0.09 - ETA: 17:12 - loss: 3.6471 - accuracy: 0.2489 - precision: 0.7693 - recall: 0.09 - ETA: 17:10 - loss: 3.6458 - accuracy: 0.2490 - precision: 0.7700 - recall: 0.09 - ETA: 17:09 - loss: 3.6444 - accuracy: 0.2494 - precision: 0.7705 - recall: 0.09 - ETA: 17:07 - loss: 3.6438 - accuracy: 0.2495 - precision: 0.7709 - recall: 0.09 - ETA: 17:05 - loss: 3.6421 - accuracy: 0.2498 - precision: 0.7719 - recall: 0.09 - ETA: 17:03 - loss: 3.6420 - accuracy: 0.2497 - precision: 0.7720 - recall: 0.09 - ETA: 17:01 - loss: 3.6421 - accuracy: 0.2497 - precision: 0.7716 - recall: 0.09 - ETA: 16:59 - loss: 3.6418 - accuracy: 0.2496 - precision: 0.7707 - recall: 0.09 - ETA: 16:57 - loss: 3.6398 - accuracy: 0.2501 - precision: 0.7712 - recall: 0.09 - ETA: 16:55 - loss: 3.6402 - accuracy: 0.2504 - precision: 0.7717 - recall: 0.09 - ETA: 16:52 - loss: 3.6407 - accuracy: 0.2504 - precision: 0.7718 - recall: 0.09 - ETA: 16:50 - loss: 3.6408 - accuracy: 0.2504 - precision: 0.7720 - recall: 0.09 - ETA: 16:48 - loss: 3.6393 - accuracy: 0.2506 - precision: 0.7718 - recall: 0.09 - ETA: 16:46 - loss: 3.6384 - accuracy: 0.2506 - precision: 0.7718 - recall: 0.09 - ETA: 16:44 - loss: 3.6380 - accuracy: 0.2507 - precision: 0.7723 - recall: 0.09 - ETA: 16:42 - loss: 3.6369 - accuracy: 0.2511 - precision: 0.7729 - recall: 0.09 - ETA: 16:40 - loss: 3.6361 - accuracy: 0.2513 - precision: 0.7732 - recall: 0.09 - ETA: 16:38 - loss: 3.6338 - accuracy: 0.2516 - precision: 0.7742 - recall: 0.09 - ETA: 16:36 - loss: 3.6342 - accuracy: 0.2516 - precision: 0.7747 - recall: 0.09 - ETA: 16:34 - loss: 3.6336 - accuracy: 0.2515 - precision: 0.7749 - recall: 0.09 - ETA: 16:33 - loss: 3.6334 - accuracy: 0.2514 - precision: 0.7743 - recall: 0.09 - ETA: 16:31 - loss: 3.6334 - accuracy: 0.2511 - precision: 0.7727 - recall: 0.09 - ETA: 16:28 - loss: 3.6336 - accuracy: 0.2511 - precision: 0.7719 - recall: 0.09 - ETA: 16:26 - loss: 3.6319 - accuracy: 0.2514 - precision: 0.7727 - recall: 0.09 - ETA: 16:25 - loss: 3.6314 - accuracy: 0.2513 - precision: 0.7723 - recall: 0.09 - ETA: 16:23 - loss: 3.6307 - accuracy: 0.2512 - precision: 0.7718 - recall: 0.09 - ETA: 16:21 - loss: 3.6299 - accuracy: 0.2511 - precision: 0.7719 - recall: 0.09 - ETA: 16:19 - loss: 3.6278 - accuracy: 0.2513 - precision: 0.7722 - recall: 0.09 - ETA: 16:17 - loss: 3.6278 - accuracy: 0.2513 - precision: 0.7720 - recall: 0.09 - ETA: 16:15 - loss: 3.6261 - accuracy: 0.2516 - precision: 0.7725 - recall: 0.09 - ETA: 16:14 - loss: 3.6271 - accuracy: 0.2513 - precision: 0.7714 - recall: 0.09 - ETA: 16:12 - loss: 3.6267 - accuracy: 0.2513 - precision: 0.7719 - recall: 0.09 - ETA: 16:09 - loss: 3.6246 - accuracy: 0.2518 - precision: 0.7715 - recall: 0.09 - ETA: 16:07 - loss: 3.6246 - accuracy: 0.2518 - precision: 0.7719 - recall: 0.09 - ETA: 16:05 - loss: 3.6243 - accuracy: 0.2517 - precision: 0.7719 - recall: 0.10 - ETA: 16:03 - loss: 3.6233 - accuracy: 0.2520 - precision: 0.7720 - recall: 0.10 - ETA: 16:02 - loss: 3.6231 - accuracy: 0.2520 - precision: 0.7719 - recall: 0.10 - ETA: 16:00 - loss: 3.6224 - accuracy: 0.2521 - precision: 0.7722 - recall: 0.10 - ETA: 15:58 - loss: 3.6222 - accuracy: 0.2523 - precision: 0.7720 - recall: 0.1004"
     ]
    }
   ],
   "source": [
    "# main_results = asyncio.run(main_future)\n",
    "main_results = await main_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_0 = main_results[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n",
    "\n",
    "# %debug\n",
    "\n",
    "histories.append(pool(train_single_fold)\n",
    "                 (fold, copy.deepcopy(cfg_0), worker_id))\n",
    "cloudpickle.loads(fn)(*args)\n",
    "\n",
    "x_col='path'\n",
    "y_col='family'\n",
    "index_col='catalog_number'\n",
    "\n",
    "full_data = fold.full_dataset.data.set_index(index_col)[[x_col, y_col]].rename(columns={x_col:'x', y_col:'y'})\n",
    "\n",
    "# full_data.index.duplicated(keep=False).sum()\n",
    "# full_data.describe(include='all')\n",
    "# full_data[full_data.index.duplicated(keep=False)].sort_index()\n",
    "\n",
    "full_data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
